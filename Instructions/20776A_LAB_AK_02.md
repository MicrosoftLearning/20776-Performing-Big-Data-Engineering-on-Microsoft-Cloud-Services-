# Lab Answer Key: Module 2: Processing Event Streams using Azure Stream Analytics

- [Lab Answer Key: Module 2: Processing Event Streams using Azure Stream Analytics](#lab-answer-key-module-2-processing-event-streams-using-azure-stream-analytics)
  - [Lab: Process event streams with Stream Analytics](#lab-process-event-streams-with-stream-analytics)
  - [Exercise 1: Create a Stream Analytics job to process Event Hub data](#exercise-1-create-a-stream-analytics-job-to-process-event-hub-data)
    - [Task 1: Create a Data Lake Storage account](#task-1-create-a-data-lake-storage-account)
    - [Task 2: Create an event hubs namespace and hub](#task-2-create-an-event-hubs-namespace-and-hub)
    - [Task 3: Create a Stream Analytics job](#task-3-create-a-stream-analytics-job)
    - [Task 4: Configure Stream Analytics job inputs](#task-4-configure-stream-analytics-job-inputs)
    - [Task 5: Configure Stream Analytics job outputs](#task-5-configure-stream-analytics-job-outputs)
    - [Task 6: Configure a Stream Analytics job query](#task-6-configure-a-stream-analytics-job-query)
    - [Task 7: Start the Stream Analytics job](#task-7-start-the-stream-analytics-job)
    - [Task 8: Generate event hub data for processing with Stream Analytics](#task-8-generate-event-hub-data-for-processing-with-stream-analytics)
    - [Task 9: Visualize Stream Analytics output using Power BI](#task-9-visualize-stream-analytics-output-using-power-bi)
    - [Task 10: View Stream Analytics output in Data Lake Store](#task-10-view-stream-analytics-output-in-data-lake-store)
    - [Task 11: Stop the TrafficAnalytics job](#task-11-stop-the-trafficanalytics-job)
  - [Exercise 2: Create a Stream Analytics job to process IoT Hub data](#exercise-2-create-a-stream-analytics-job-to-process-iot-hub-data)
    - [Task 1: Create an IoT Hub](#task-1-create-an-iot-hub)
    - [Task 2: Create a new Stream Analytics job](#task-2-create-a-new-stream-analytics-job)
    - [Task 3: Configure Stream Analytics job inputs](#task-3-configure-stream-analytics-job-inputs)
    - [Task 4: Configure Stream Analytics job outputs](#task-4-configure-stream-analytics-job-outputs)
    - [Task 5: Configure the Stream Analytics job query](#task-5-configure-the-stream-analytics-job-query)
    - [Task 6: Start the Stream Analytics job](#task-6-start-the-stream-analytics-job)
    - [Task 7: Generate IoT hub data for processing with Stream Analytics](#task-7-generate-iot-hub-data-for-processing-with-stream-analytics)
    - [Task 8: Visualize Stream Analytics output using Power BI](#task-8-visualize-stream-analytics-output-using-power-bi)
    - [Task 9: View Stream Analytics output in Azure Data Lake Store](#task-9-view-stream-analytics-output-in-azure-data-lake-store)
    - [Task 10: Stop the PatrolCarAnalytics job](#task-10-stop-the-patrolcaranalytics-job)
  - [Exercise 3: Reconfigure a Stream Analytics job to send output through a Service Bus queue](#exercise-3-reconfigure-a-stream-analytics-job-to-send-output-through-a-service-bus-queue)
    - [Task 1: Create a Service Bus namespace and queue](#task-1-create-a-service-bus-namespace-and-queue)
    - [Task 2: Reconfigure the IoT Hub](#task-2-reconfigure-the-iot-hub)
    - [Task 3: Reconfigure the PatrolCarAnalytics Stream Analytics job](#task-3-reconfigure-the-patrolcaranalytics-stream-analytics-job)
    - [Task 4: Start the Stream Analytics job](#task-4-start-the-stream-analytics-job)
    - [Task 5: Prepare an application to receive Stream Analytics data using a Service Bus](#task-5-prepare-an-application-to-receive-stream-analytics-data-using-a-service-bus)
    - [Task 6: Generate IoT Hub data for processing with Stream Analytics](#task-6-generate-iot-hub-data-for-processing-with-stream-analytics)
  - [Exercise 4: Reconfigure a Stream Analytics job to process both event hub and static file data](#exercise-4-reconfigure-a-stream-analytics-job-to-process-both-event-hub-and-static-file-data)
    - [Task 1: Create a Blob storage account for holding stolen vehicle data](#task-1-create-a-blob-storage-account-for-holding-stolen-vehicle-data)
    - [Task 2: Examine the StolenVehiclesReport.csv file](#task-2-examine-the-stolenvehiclesreportcsv-file)
    - [Task 3: Use Azure Storage Explorer to upload a StolenVehiclesReport.csv to the Blob storage container](#task-3-use-azure-storage-explorer-to-upload-a-stolenvehiclesreportcsv-to-the-blob-storage-container)
    - [Task 4: Update the event hub and add two more consumer groups](#task-4-update-the-event-hub-and-add-two-more-consumer-groups)
    - [Task 5: Reconfigure the TrafficAnalytics Stream Analytics job inputs](#task-5-reconfigure-the-trafficanalytics-stream-analytics-job-inputs)
    - [Task 6: Reconfigure the TrafficAnalytics Azure Stream Analytics job outputs](#task-6-reconfigure-the-trafficanalytics-azure-stream-analytics-job-outputs)
    - [Task 7: Reconfigure the TrafficAnalytics Stream Analytics job query](#task-7-reconfigure-the-trafficanalytics-stream-analytics-job-query)
    - [Task 8: Start the TrafficAnalytics Stream Analytics job](#task-8-start-the-trafficanalytics-stream-analytics-job)
    - [Task 9: Generate event hub data for processing with Stream Analytics](#task-9-generate-event-hub-data-for-processing-with-stream-analytics)
    - [Task 10: Visualize Stream Analytics output using Power BI](#task-10-visualize-stream-analytics-output-using-power-bi)
    - [Task 11: View Stream Analytics output in Data Lake Store](#task-11-view-stream-analytics-output-in-data-lake-store)
  - [Exercise 5: Use multiple Stream Analytics jobs to process event hub, IoT hub and static file data, and output results using a Service Bus and custom application](#exercise-5-use-multiple-stream-analytics-jobs-to-process-event-hub-iot-hub-and-static-file-data-and-output-results-using-a-service-bus-and-custom-application)
    - [Task 1: Create a new Service Bus topic and add a subscription](#task-1-create-a-new-service-bus-topic-and-add-a-subscription)
    - [Task 2: Reconfigure the IoT hub and add a new consumer group](#task-2-reconfigure-the-iot-hub-and-add-a-new-consumer-group)
    - [Task 3: Reconfigure the event hub and add a new consumer group](#task-3-reconfigure-the-event-hub-and-add-a-new-consumer-group)
    - [Task 4: Reconfigure the TrafficAnalytics Azure Stream Analytics job inputs](#task-4-reconfigure-the-trafficanalytics-azure-stream-analytics-job-inputs)
    - [Task 5: Reconfigure the TrafficAnalytics Stream Analytics job outputs](#task-5-reconfigure-the-trafficanalytics-stream-analytics-job-outputs)
    - [Task 6: Reconfigure the TrafficAnalytics Stream Analytics job query](#task-6-reconfigure-the-trafficanalytics-stream-analytics-job-query)
    - [Task 7: Start the TrafficAnalytics Azure and PatrolCarAnalytics Stream Analytics jobs](#task-7-start-the-trafficanalytics-azure-and-patrolcaranalytics-stream-analytics-jobs)
    - [Task 8: Generate event hub and IoT hub data for processing with Stream Analytics](#task-8-generate-event-hub-and-iot-hub-data-for-processing-with-stream-analytics)
    - [Task 9: Start an application to receive Stream Analytics data using a Service Bus topic](#task-9-start-an-application-to-receive-stream-analytics-data-using-a-service-bus-topic)
  - [Exercise 6: Use the Azure portal and Azure PowerShell to manage and scale Stream Analytics jobs](#exercise-6-use-the-azure-portal-and-azure-powershell-to-manage-and-scale-stream-analytics-jobs)
    - [Task 1: Add a monitoring alert to a Stream Analytics job](#task-1-add-a-monitoring-alert-to-a-stream-analytics-job)
    - [Task 2: Use the Azure portal to scale up a Stream Analytics job](#task-2-use-the-azure-portal-to-scale-up-a-stream-analytics-job)
    - [Task 3: Use Azure PowerShell to stop a Stream Analytics job](#task-3-use-azure-powershell-to-stop-a-stream-analytics-job)
    - [Task 4: Use Azure PowerShell to scale down and restart a Stream Analytics job](#task-4-use-azure-powershell-to-scale-down-and-restart-a-stream-analytics-job)
    - [Task 5: Use job diagrams to visualize Stream Analytics job configurations](#task-5-use-job-diagrams-to-visualize-stream-analytics-job-configurations)
    - [Task 6: Lab closedown](#task-6-lab-closedown)

## Lab: Process event streams with Stream Analytics

> **Important**: Due to the CPU-intensive nature of some of the tasks performed by the applications in this lab, it is recommended that you assign at least 4 virtual processors to the 20776A-LON-DEV VM before starting this lab. To do this, perform the following steps:
>   1. Shutdown the 20776A-LON-DEV VM if it is currently running
>   2. Using Hyper-V Manager, right-click the 20776A-LON-DEV VM, and then click **Settings**
>   3. Click **Processor**
>   4. In the **Processor** pane, increase **Number of virtual processors** to 4
>   5. Click **OK**
>   6. Restart the 20776A-LON-DEV VM


## Exercise 1: Create a Stream Analytics job to process Event Hub data

### Task 1: Create a Data Lake Storage account

1. Ensure that the **MT17B-WS2016-NAT**, **20776A-LON-DC**, and **20776A-LON-DEV** virtual machines are running, and then log on to **20776A-LON-DEV** as **ADATUM\AdatumAdmin** with the password **Pa55w.rd**.
2. On the Start menu, type **Internet Explorer**, and then press Enter.
3. In Internet Explorer, go to http://portal.azure.com, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
4. In the Azure portal, click **+ Create a resource**, click **Storage**, and then click **Data Lake Storage Gen1**.
5. On the **New Data Lake Storage Gen1** blade, in the **Name** box, type **adls&lt;_your name_&gt;&lt;_date_&gt;**.
6. Under **Resource group**, click **Create new**, type **CamerasRG**, and then click **OK**.
7. In the **Location** list, select your nearest location from the currently available Data Lake Store regions.
8. Leave all other settings at their defaults, and click **Create**.
9. Wait until the storage has deployed before continuing with the lab.

### Task 2: Create an event hubs namespace and hub

1. In the Azure portal, click **+ Create a resource**, click **Internet of Things**, and then click **Event Hubs**.
2. On the **Create Namespace** blade, in the **Name** box, type **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
3. In the **Pricing tier** drop-down list box, click **Standard**
4. In the **Resource group** drop-down list box, click **CamerasRG**.
5. In the **Location** list, select the same location as you used for the Data Lake Store.
6. Set **Throughput Units** to 1.
7. Select **Enable Auto-Inflate**, and set **Auto-Inflate Maximum Throughput Units** to 4.
8. Click **Create**.
9. Wait until the namespace has deployed before continuing with the lab.
10. Click **All resources**, click **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**, and then click **+ Event Hub**.
11. On the **Create Event Hub** blade, in the **Name** box, type **traffic**.
12. Set the **Partition Count** to **16**.
13. Leave all other settings at their defaults, and click **Create**.
14. Wait until the event hub has deployed before continuing with the lab.
15. On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Entities**, click **Event Hubs**, and then click **traffic**.
16. On the **traffic** blade, click **+ Consumer group**.
17. On the **Create consumer group** blade, in the **Name** box, type **cameradatafeed**, and then click **Create**.
18. On the **traffic** blade, click **+ Consumer group** again.
19. On the **Create consumer group** blade, in the **Name** box, type **cameradatafeed2**, and then click **Create**.
20. Close the **traffic** blade.
21. On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt; - Event Hubs** blade, under **Settings**, click **Shared access policies**, and then click **RootManageSharedAccessKey**.
22. Next to the **Primary Key**, click the **Click to copy** button, to copy the primary key to the clipboard.
23. On the Start menu, type **Notepad**, and then press Enter.
24. In Notepad, type **Event hub primary key**, and press Enter.
25. On the **Edit** menu, click **Paste**, to store the primary key.
26. On the **File** menu, click **Save**.
27. In the **Save As** dialog box, go to **E:\\Labfiles\\Lab02**, in the **File name** box, type **Config\_details.txt**, and then click **Save**.

### Task 3: Create a Stream Analytics job

1. Return to the Azure portal, click **+ Create a resource**, click **Analytics**, and then click **Stream Analytics job**.
2. On the **New Stream Analytics Job** blade, in the **Job name** box, type **TrafficAnalytics**.
3. In the **Resource group** drop-down list box, click **CamerasRG**.
4. In the **Location** list, select the same location as you used for the Data Lake Store, and then click **Create**.
5. Wait until the Stream Analytics job has deployed before continuing with the lab.

### Task 4: Configure Stream Analytics job inputs

1. In the Azure portal, click **All resources**, and then click **TrafficAnalytics**.
2. On the **TrafficAnalytics** blade, under **Job topology**, click **Inputs**, click **+ Add stream input**, and then click **Event Hub**.
3. On the **Event Hub New input** blade, enter the following details:
    - **Input alias**: CameraDataFeed
    - **Provide Event Hub settings manually**: selected
    - **Service Bus namespace**: camerafeeds&lt;_your name_&gt;&lt;_date_&gt; as you created earlier
    - **Event Hub name**: traffic
    - **Event Hub policy name**: RootManageSharedAccessKey
    - **Event Hub policy key**: Paste the key you copied to the Config\_details.txt file
    - **Event hub consumer group**: cameradatafeed
4. Leave all other settings at their defaults, and then click **Save**.
5. Wait until the input has been successfully created before continuing with the lab.
6. On the **TrafficAnalytics - Inputs** blade, click **+ Add stream input**, and then click **Event Hub**.
7. On the **New input** blade, enter the following details:
    - **Input alias**: CameraDataFeed2
    - **Provide Event Hub settings manually**: selected
    - **Service Bus namespace**: camerafeeds&lt;_your name_&gt;&lt;_date_&gt; as you created earlier
    - **Event Hub name**: traffic
    - **Event Hub policy name**: RootManageSharedAccessKey
    - **Event Hub policy key**: Paste the key you copied to Config\_details.txt
    - **Event Hub consumer group**: cameradatafeed2
8. Leave all other settings at their defaults, and click **Save**.
9. Wait until the input has been successfully created before continuing with the lab.

### Task 5: Configure Stream Analytics job outputs

1. On the **TrafficAnalytics - Inputs** blade, under **Job topology**, click **Outputs**, click **+ Add**, and then click **Power BI**.
2. On the **Power BI New output** blade, enter the following details, and then click **Save**:
    - **Output alias**: VisualData
    - **Dataset Name**: TrafficData
    - **Table Name**: TrafficData
    - Click **Authorize**, and sign in using your Power BI credentials. If you don't have a PowerBI account, click **Sign up**. Follow the sign-up process, and then return to the **Power BI New output** blade in the Azure portal.
3. Wait until the output has been successfully created before continuing with the lab.
4. On the **TrafficAnalytics - Outputs** blade, click **+ Add**, and then click **Data Lake Storage Gen1**.
5. On the **New output** blade, enter the following details:
    - **Output alias**: StoredData
    - **Account name**: adls&lt;_your name_&gt;&lt;_date_&gt;
    - **Path prefix pattern**: SpeedData/{date}/{time}
    - Click **Authorize**
6. Leave all other settings at their defaults, and click **Save**.
7. Wait until the output has been successfully created before continuing with the lab.

### Task 6: Configure a Stream Analytics job query

1. On the **TrafficAnalytics - Outputs** blade, under **Job topology**, click **Query**, and then replace the template query text with the following SELECT statements:

    ```SQL
    SELECT
      CameraID,VehicleRegistration,Speed,SpeedLimit,LocationLatitude,LocationLongitude,Time
    INTO
      StoredData
    FROM
      CameraDataFeed

    SELECT
      CameraID, AVG(Speed) AS AvgSpeed
    INTO
      VisualData
    FROM
      CameraDataFeed2
    TIMESTAMP BY
      Time
    GROUP BY
      CameraID, TumblingWindow(second, 30)
    ```

    You can copy the preceding commands from the file **E:\\Labfiles\\Lab02\\ASAquery1.txt**.

2. Click **Save**, and then click **Yes**.

### Task 7: Start the Stream Analytics job

1. On the **TrafficAnalytics - Query** blade, click **Overview**, and then click **Start**.
2. On the **Start job TrafficAnalytics** blade, click **Now**, and then click **Start**.
3. Wait until the job has successfully started before continuing with the lab.

### Task 8: Generate event hub data for processing with Stream Analytics

1. On the Start menu, type **Visual Studio 2017**, and then press Enter.
2. On the **File** menu, point to **Open**, and then click **Project/Solution**.
3. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\SpeedCameraDevice** folder, click **SpeedCameraDevice.sln**, and then click **Open**.
4. In Solution Explorer, double-click **App.config**.
5. In App.config, in the **appSettings** section, replace the text **YourNamespace** in the **Endpoint** value with **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
6. Also in the **Endpoint** value, replace the text **YourPrimaryKey** with the primary key for the **RootManageSharedAccessKey** policy for the Event Hubs namespace that you copied to the Config_details.txt file.
7. In Solution Explorer, right-click **SpeedCameraDriver**, and then click **Set as StartUp Project**.
8. On the **Build** menu, click **Build Solution**. Verify that the app compiles successfully.
9. On the **Debug** menu, click **Start Without Debugging**. The app opens a console window displaying generated speed camera data that is being sent to the event hub.

### Task 9: Visualize Stream Analytics output using Power BI

1. In Internet Explorer, open a new tab, and go to **https://powerbi.microsoft.com**.
2. In Power BI, if prompted, sign in using your Power BI account credentials.
3. Click **My Workspace**, and then click **DataSets**.
4. Verify that a streaming dataset named **TrafficData** is available (if this does not appear, wait a few minutes, and then refresh the page).
5. Click **+ Create**, and then click **Dashboard**.
6. In the **Create dashboard** dialog box, in the **Dashboard name** box, type **Traffic**, and then click **Create**.
7. Click **+ Add tile**.
8. In the **Add tile** pane, in the **REAL-TIME DATA** section, click **Custom Streaming Data**, and then click **Next**.
9. In the **Add a custom streaming data tile** pane, under **YOUR DATASETS**, click **TrafficData**, and then click **Next**.
10. In the **Add a custom streaming data tile** pane, in the **Visualization Type** list, click **Clustered column chart**.
11. Under **Axis**, click **Add value**, and then select **cameraid**.
12. Under **Value**, click **Add value**, and then select **avgspeed**.
13. Under **Time window to display**, select **30 seconds**, and then click **Next**.
14. In the **Tile details** pane, in the **Title** box, type **Camera speeds**, and then click **Apply**.
15. Resize the tile so that it occupies most of the space on the dashboard.
16. Leave the tile to display for a few minutes; note that it summarizes information about the average speeds recorded by each camera during the last 30-second interval.

### Task 10: View Stream Analytics output in Data Lake Store

1. Switch to the Azure portal, click **All resources**, and then click **adls&lt;_your name_&gt;&lt;_date_&gt;**.
2. On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **Data explorer**.
3. On the **adls&lt;_your name_&gt;&lt;_date_&gt; Data Lake Storage Gen1** blade, click **SpeedData**, and then click down through all the subfolders.
4. Click the log file to view the contents in the **File preview** blade; verify that the data includes the fields you specified in your Azure Stream Analytics query.
5. Close the **File preview** blade.

### Task 11: Stop the TrafficAnalytics job

1. Click **All resources**, and then click **TrafficAnalytics**.
2. On the **TrafficAnalytics** blade, click **Stop**, and then click **Yes**.
3. Switch to the Visual Studio app window (where the data is being generated), and press Enter to stop the app.

>**Result**: In this exercise, you created an Azure Data Lake Store, an event hubs namespace, and a Stream Analytics job. You used Stream Analytics to process event hubs data, and viewed the results in a Power BI dashboard and in Data Lake Store.

## Exercise 2: Create a Stream Analytics job to process IoT Hub data

### Task 1: Create an IoT Hub

1. In the Azure portal, click **+ Create a resource**, click **Internet of Things**, and then click **IoT Hub**.
2. On the **IoT Hub** blade, in the **Resource group** list, click **CamerasRG**.
3. In the **Region** list, select the same region that you used in Exercise 1.
4. In the **IoT Hub Name** box, type **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
5. Click the **Size and scale** tab.
6. Under **SCALE TIER AND UNITS**, in the **Pricing and scale tier** drop-down list box, click **B1: Basic tier**.
7. Click the **Review + create** tab.
8. Click **Create**
9. Wait until the IoT hub has deployed before continuing with the lab.
10. Click **All Resources**, and then click **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
11. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Settings**, click **Built-in endpoints**.
12. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt; - Built-in endpoints**, blade, under **Consumer groups**, in the box, type **patrolcars**, in the next box, type **patrolcars2**, and then move the mouse to the next box. The changes should be saved automatically.
13. Switch to the Azure portal, and on the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Settings**, click **Shared access policies**.
14. In the **Policy** list, click **iothubowner**.
15. In the **iothubowner** blade, next to the **Primary key**, click the **Click to copy** button, to copy the string to the clipboard.
16. Switch to Notepad, press CTRL+END, and then press Enter.
17. Type **IoT hub settings**, and then press Enter.
18. On the **Edit** menu, click **Paste**, to store the connection string.
19. Switch to the Azure portal, and close the **iothubowner** blade.

### Task 2: Create a new Stream Analytics job

1. In the Azure portal, click **+ Create a resource**, click **Analytics**, and then click **Stream Analytics job**.
2. On the **New Stream Analytics Job** blade, in the **Job name** box, type **PatrolCarAnalytics**.
3. Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
4. In the **Location** list, select the same location that you used for the Data Lake Store.
5. Set **Streaming units** to 1, and then click **Create**.
6. Wait until the Stream Analytics job has deployed before continuing with the lab.

### Task 3: Configure Stream Analytics job inputs

1. In the Azure portal, click **All resources**, and then click **PatrolCarAnalytics**.
2. On the **PatrolCarAnalytics** blade, under **Job topology**, click **Inputs**, click **+ Add stream input**, and then click **IoT Hub**.
3. On the **IoT Hub New input** blade, enter the following details:
    - **Input alias**: PatrolCarDataFeed
    - **Select IoT Hub from your subscriptions**: selected
    - **IoT Hub**: patrolcars&lt;_your name_&gt;&lt;_date_&gt;
    - **Consumer group**: patrolcars
4. Leave all other settings at their defaults, and click **Save**.
5. Wait until the input has been successfully created before continuing with the lab.
6. On the **PatrolCarAnalytics - Inputs** blade, click **+ Add stream input**, and then click **IoT Hub**.
7. On the **IoT Hub New input** blade, enter the following details:
    - **Input alias**: PatrolCarDataFeed2
    - **Select IoT Hub from your subscriptions**: selected
    - **IoT Hub**: patrolcars&lt;_your name_&gt;&lt;_date_&gt;
    - **Consumer group**: patrolcars2
8. Leave all other settings at their defaults, and click **Save**.
9. Wait until the input has been successfully created before continuing with the lab.

### Task 4: Configure Stream Analytics job outputs

1. On the **PatrolCarAnalytics - Inputs** blade, under **Job topology**, click **Outputs**, click **+ Add**, and then click **Power BI**.
2. On the **Power BI New output** blade, enter the following details, and then click **Save**:
    - **Output alias**: PatrolCarVisualData
    - **Dataset Name**: PatrolCarData
    - **Table Name**: RealTimeData
    - Click **Authorize**, and (if prompted) enter your Power BI credentials

    > **Note:** The table name is important. You will use the ArcGIS Map control in Power BI to visualize the data, and this control always expects the data source to be named **RealTimeData**.

3. Wait until the output has been successfully created before continuing with the lab.
4. On the **PatrolCarAnalytics - Outputs** blade, click **+ Add**, and then click **Data Lake Storage Gen1**.
5. On the **Data Lake Store New output** blade, enter the following details:
    - **Output alias**: PatrolCarStoredData
    - **Select Data Lake Store from your subscriptions**: Selected
    - **Account name**: Your Data Lake Storage account
    - **Path prefix pattern**: PatrolCarData/{date}/{time}
    - Click **Authorize**
6. Leave all other settings at their defaults, and click **Save**.
7. Wait until the output has been successfully created before continuing with the lab.

### Task 5: Configure the Stream Analytics job query

1. On the **PatrolCarAnalytics - Outputs** blade, under **Job topology**, click **Query**, and then replace the template query text with the following:

    ```SQL
    SELECT
      CarID,LocationLatitude,LocationLongitude,System.TimeStamp AS Time
    INTO
      PatrolCarVisualData
    FROM
      PatrolCarDataFeed

    SELECT
      *
    INTO
      PatrolCarStoredData
    FROM
      PatrolCarDataFeed2
    ```

You can copy the preceding commands from the file **E:\\Labfiles\\Lab02\\ASAquery2.txt**.

2. Click **Save**, and then click **Yes**.

### Task 6: Start the Stream Analytics job

1. On the **PatrolCarAnalytics - Query** blade, click **Overview**.
2. On the **PatrolCarAnalytics Strean Analytics job** blade, click **Start**.
3. On the **Start job** blade, click **Now**, and then click **Start**.
4. Wait until the job has successfully started before continuing with the lab.

### Task 7: Generate IoT hub data for processing with Stream Analytics

1. Switch to Visual Studio.
2. On the **File** menu, point to **Open**, and then click **Project/Solution**.
3. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\PatrolCarDevice** folder, click **PatrolCarDevice.sln**, and then click **Open**.
4. In Solution Explorer, double-click **App.config**.
5. In App.config, in the **appSettings** section, in the **IoTHubConnectionString** and **IotHubUri** values, replace the text **YourIoTHub** with **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
6. In App.config, in the **appSettings** section, in the **IoTHubConnectionString** value, replace the text **YourPrimaryKey** with the primary key you copied to **Config\_details.txt**.
7. On the **Build** menu, click **Build Solution**.
8. Verify that the app compiles successfully, and then click **Start**. The app opens a console window displaying the generated positions of patrol cars that are sent to the IoT hub.

### Task 8: Visualize Stream Analytics output using Power BI

1. In Internet Explorer, switch to the Power BI page.
2. Click **My Workspace**, and then click **DataSets**. Verify that a streaming dataset named **PatrolCarData** is available (if this does not appear, wait a few minutes then refresh the page).
3. Click **+ Create**, and then click **Report**.
4. In the **Create report** dialog box, click **PatrolCarData**, and then click **Create**.
5. In the **Fields** pane, select all the data fields.
6. In the **Visualizations** pane, click **ArcGIS Maps for Power BI**. Note that the ArcGIS Maps visualization will display an error message initially until it is configured properly.
7. In the **Visualizations** pane, in the **Latititude** box, click the drop-down arrow by the **Average of locationlatitude** value, and then click **Don't summarize**.
8. In the **Longitude** box, click the drop-down arrow by the **Average of locationlongtude** value, and then click **Don't summarize**. The ArcGIS Maps visualization should now be rendered without any errors
9. Resize the map control to make it larger and zoom in. The report shows a history of the movements of each patrol car.

    > **Note:** The data displayed by the report is cumulative; you need to click **Refresh** to update the report.

### Task 9: View Stream Analytics output in Azure Data Lake Store

1. Return to the Azure portal.
2. Click **All resources**, and then click **adls&lt;_your name_&gt;&lt;_date_&gt;**.
3. On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **Data explorer**.
4. On the **adls&lt;_your name_&gt;&lt;_date_&gt; Data Lake Storage Gen1** blade, click **PatrolCarData**, and then click through all of the subfolders.
5. Click the JSON file to view the contents in the **File preview** blade. Verify that the data includes the fields you specified in your Stream Analytics query.

### Task 10: Stop the PatrolCarAnalytics job

1. Click **All resources**, and then click **PatrolCarAnalytics**.
2. On the **PatrolCarAnalytics** blade, click **Stop**, and then click **Yes**.
3. Switch to the Visual Studio app window (where the data is being generated), and press Enter to stop the app.

>**Result**: In this exercise, you created a Data Lake Store, an IoT hub, and a new Stream Analytics job. You used Stream Analytics to process IoT hub data, and viewed the results in a Power BI report and in Data Lake Store.

## Exercise 3: Reconfigure a Stream Analytics job to send output through a Service Bus queue

### Task 1: Create a Service Bus namespace and queue

1. In the Azure portal, click **+ Create a resource**, click **Integration**, and then click **Service Bus**.
2. On the **Create namespace** blade, in the **Name** box, type **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
3. In the **Pricing tier** drop-down list box, select **Standard**.
4. Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
5. In the **Location** list, select the same location that you used for the Data Lake Store, and click **Create**.
6. Wait until the Service Bus namespace has been created before continuing with the lab.
7. Click **All resources**, and then click **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
8. On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Settings**, click **Shared access policies**, and then click **RootManageSharedAccessKey**.
9. Next to the **Primary Key**, click the **Click to copy** button, to copy the primary key to the clipboard.
10. Switch to Notepad.
11. In Notepad, press CTRL+END, and then press Enter.
12. Type **Service bus primary key**, and then press Enter.
13. On the **Edit** menu, click **Paste**, to store the primary key.
14. Return to the Azure portal.
15. On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt; - Shared access policies** blade, under **Entities**, click **Queues**.
16. On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt; - Queues** blade, click **+ Queue**.
17. On the **Create queue** blade, in the **Name** box, type **LocationAlerts**.
18. Leave all other settings at their defaults, and click **Create**.
19. Wait until the queue has been successfully created before continuing with the lab.

### Task 2: Reconfigure the IoT Hub

1. Click **All resources**, and then click **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
2. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Settings**, click **Built-in endpoints**.
3. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt; - Built-in endpoints** blade, under **Consumer groups**, in the empty box at the end of the list, type **patrolcars3**.
5. Move the mouse to the next box to save the changes.

### Task 3: Reconfigure the PatrolCarAnalytics Stream Analytics job

1. Click **All resources**, and then click **PatrolCarAnalytics**.
2. On the **PatrolCarAnalytics** blade, under **Job topology**, click **Inputs**, click **+ Add stream input**, and then click **IoT Hub**.
3. On the **New input** blade, enter the following details:
    - **Input alias**: PatrolCarDataFeed3
    - **Select IoT Hub from your subscriptions**: Selected
    - **IoT Hub**: Specify your IoT hub
    - **Consumer group**: patrolcars3
4. Leave all other settings at their defaults, and click **Save**.
5. Wait until the input has been successfully created before continuing with the lab.
6. On the **PatrolCarAnalytics - Inputs** blade, under **Job topology**, click **Outputs**, click **+ Add**, and then click **Service Bus queue**
7. On the **New output** blade, enter the following details:
    - **Output alias**: PatrolCarLocationAlerts
    - **Select queue from your subscriptions**: Selected
    - **Servie Bus namespace**: locationalerts&lt;_your name_&gt;&lt;_date_&gt;
    - **Queue name**: locationalerts
8. Leave all other settings at their defaults, and click **Save**.
9. Wait until the output has been successfully created before continuing with the lab.
10. On the **PatrolCarAnalytics - Outputs** blade, under **Job topology**, click **Query**, and then add the following statement to the end of the existing query:

    ``` SQL
    SELECT
      CarID,CarNum,LocationLatitude,LocationLongitude,Speed
    INTO
      PatrolCarLocationAlerts
    FROM
      PatrolCarDataFeed3
    ```

    You can copy the preceding commands from the file **E:\\Labfiles\\Lab02\\ASAquery3.txt**.

11.  Click **Save**, and then click **Yes**.

### Task 4: Start the Stream Analytics job

1. On the **PatrolCarAnalytics - Query** blade, click **Overview**, and then click **Start**.
2. On the **Start job** blade, click **Now**, and then click **Start**.
3. Wait until the job has successfully started before continuing with the lab.

### Task 5: Prepare an application to receive Stream Analytics data using a Service Bus

1. On the desktop, start a new instance of **Visual Studio**.
2. In Visual Studio, on the **File** menu, point to **Open**, and then click **Project/Solution**.
3. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\LocationAlerts** folder, click **LocationAlerts.sln**, and click **Open**; this project displays the movements of patrol cars that it receives from the queue.
4. In Solution Explorer, double-click **ConfigSettings.txt**.
5. In ConfigSettings.txt, replace **YourServiceBusName** with **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
6. In ConfigSettings.txt, replace **YourPrimaryKey** with the primary key from the service bus connection string you copied to Notepad in Task 1 of this exercise.
7. On the **Debug** toolbar, esnure that the **Solution Platform** drop-down list box is set to **x64** (not **ARM**).
8. **On the **Build** menu, click **Build Solution**.
9. Verify that the app compiles successfully, and then click **Local Machine** (Start). The app displays a map (of London), but not the positions of any patrol cars yet.

### Task 6: Generate IoT Hub data for processing with Stream Analytics

1. Switch to the first instance of Visual Studio, with the **PatrolCarDevice** solution..
2. Click **Start** to run the **PatrolCarDevice** app, to start generating patrol car movements.
3. Switch to the map displayed by the LocationAlerts app.
4. Verify that, after a few seconds, the locations of patrol cars start appearing on the map—and that these positions slowly change as patrol cars are driven around. You might have to zoom out to see all the patrol cars.
5. Allow the system to run for a while, so that you see the patrol car movements.
6. Switch to the Azure portal.
7. Click **All resources**, and then click **PatrolCarAnalytics**.
8. On the **PatrolCarAnalytics** blade, click **Stop**, and then click **Yes**.
9. Return to the Visual Studio app window where the data is being generated, and press Enter to stop the app.
10. Close the LocationAlerts window displaying the map.
11. Close both instances of Visual Studio.

>**Result**: In this exercise, you created an Azure Service Bus namespace, and reconfigured an existing IoT hub and an existing Stream Analytics job. You used Stream Analytics to process IoT hub data and to send results to a Service Bus queue. Finally, used a custom application to visualize the data received from the Service Bus.

## Exercise 4: Reconfigure a Stream Analytics job to process both event hub and static file data

### Task 1: Create a Blob storage account for holding stolen vehicle data

1. In the Azure portal, click **+ Create a resource**, click **Storage**, and then click **Storage account - blob, file, table, queue**.
2. On the **Create storage account** blade, in the **Resource group**, list, click **CamerasRG**.
3. In the **Name** box, type **datastore&lt;_your name_&gt;&lt;_date_&gt;**.
4. In the **Location** list, select the same location that you used for the Data Lake Store.
5. In the **Account kind** list, select **Blob storage**
6. Leave all other details at their defaults, click **Review + create**, and then click **Create**.
7. Wait until the storage account has been successfully created before continuing with the lab.
8. Click **All resources**, and then click **datastore&lt;_your name_&gt;&lt;_date_&gt;**.
9. On the **datastore&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Blob Service**, click **Blobs**.
10. On the **datastore&lt;_your name_&gt;&lt;_date_&gt; - Blobs** blade, click **+ Container**.
11. In the **New container** dialog box, in the **Name** box, type **stolenvehicledata**, and then click **OK**.

### Task 2: Examine the StolenVehiclesReport.csv file

1. On the Windows taskbar, click **File Explorer**.
2. In File Explorer, go to **E:\\Labfiles\\Lab02**, and then double-click **StolenVehiclesReport.csv**.
3. Examine the contents of this file; it contains the registration number, date stolen, and date recovered for stolen vehicles. If a vehicle is still missing, the date recovered is empty.
4. Close Microsoft Excel, without saving any changes.

### Task 3: Use Azure Storage Explorer to upload a StolenVehiclesReport.csv to the Blob storage container

1. On the Start menu, type **Microsoft Azure Storage Explorer**, and then click the**Microsoft Azure Storage Explorer** desktop app.
2. In the **Connect to Azure Storage** dialog box, select **Add an Azure Account**, and then click **Sign in**.
3. In the **Sign in to your account** dialog box, enter the credentials of the Microsoft account that is associated with your Azure Learning Pass subscription, and then click **Sign in**.
4. In the left pane, under your Azure Learning Pass subscription, under **Storage Accounts**, expand **datastore&lt;_your name_&gt;&lt;_date_&gt;**.
5. Expand **Blob Containers**, and then click **stolenvehicledata**.
6. In the right pane, click **Upload**, and then click **Upload Files**.
7. In the **Upload files** dialog box, click the ellipsis (**...**).
8. In the **Select files to upload** dialog box, go to **E:\\Labfiles\\Lab02**, click **StolenVehiclesReport.csv**, and then click **Open**.
9. In the **Upload files** dialog box, click **Upload**.
10. When the upload has completed, close Microsoft Azure Storage Explorer.

### Task 4: Update the event hub and add two more consumer groups

1. Return to the Azure portal, click **All resources**, and then click **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
2. On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Entities**, click **Event Hubs**, and then click **traffic**.
3. On the **traffic** blade, click **+ Consumer Group**.
4. On the **Create consumer group** blade, in the **Name** box, type **stolenvehiclefeed1**, and then click **Create**.
5. On the **traffic** blade, click **+ Consumer Group**.
6. On the **Create consumer group** blade, in the **Name** box, type **stolenvehiclefeed2**, and then click **Create**.

### Task 5: Reconfigure the TrafficAnalytics Stream Analytics job inputs

1. Click **All resources**, and then click **TrafficAnalytics**.
2. On the **TrafficAnalytics** blade, under **Job topology**, click **Inputs**, click **+ Add reference input**, and then click **Blob storage**.
3. On the **Blob Storage New input** blade, enter the following details:
    - **Input alias**: StolenVehicleData
    - **Select Blob storage from your subscriptions**: selected
    - **Storage account**: datastore&lt;_your name_&gt;&lt;_date_&gt;
    - **Container**: stolenvehicledata
    - **Path pattern**: StolenVehiclesReport.csv
    - **Event serialization format**: CSV
4. Leave all other settings at their defaults, and click **Save**.
5. Wait until the input has been successfully created before continuing with the lab.
6. On the **TrafficAnalytics - Inputs** blade, click **+ Add stream input**, and then click **Event Hub**.
7. On the **Event Hub New input** blade, enter the following details:
    - **Input alias**: StolenVehicleFeed1
    - **Select Event Hub from your subscriptions**: selected
    - **Event Hub namespace**: camerafeeds_your name_&gt;&lt;_date_&gt;
    - **Event Hub name**: traffic
    - **Event Hub consumer group**: stolenvehiclefeed1
8. Leave all other settings at their defaults, and click **Save**.
9. Wait until the input has been successfully created before continuing with the lab.
10. On the **TrafficAnalytics - Inputs** blade, click **+ Add stream input**, and then click **Event Hub**.
11. On the **Event Hub New input** blade, enter the following details:
    - **Input alias**: StolenVehicleFeed2
    - **Select Event Hub from your subscriptions**: selected
    - **Event Hub namespace**: camerafeeds_your name_&gt;&lt;_date_&gt;
    - **Event Hub name**: traffic
    - **Event hub consumer group**: stolenvehiclefeed2
12. Leave all other settings at their defaults, and click **Save**.
13. Wait until the input has been successfully created before continuing with the lab.

### Task 6: Reconfigure the TrafficAnalytics Azure Stream Analytics job outputs

1. On the **TrafficAnalytics - Inputs** blade, under **Job topology**, click **Outputs**, click **+ Add**, and then click **Power BI**.
2. On the **Power BI New output** blade, enter the following details, and then click **Save**:
    - **Output alias**: StolenCarAlerts
    - **Dataset name**: StolenCarAlerts
    - **Table name**: StolenCarAlerts
    - Click **Authorize**, and (if prompted) enter your Power BI credentials.
3. Wait until the output has been successfully created before continuing with the lab.
4. On the **TrafficAnalytics - Outputs** blade, click **+ Add**, and then click **Data Lake Storage Gen1**.
5. On the **Data Lake Store New output** blade, enter the following details:
    - **Output alias**: StolenCarObservations
    - **Select Data Lake Store from your subscriptions**: selected
    - **Account name**: adls_your name_&gt;&lt;_date_&gt;
    - **Path prefix pattern**: StolenCarObservations/{date}/{time}
    - Click **Authorize**, and (if prompted) enter your Azure credentials
6. Leave all other settings at their defaults, and click **Save**.
7. Wait until the output has been successfully created before continuing with the lab.

### Task 7: Reconfigure the TrafficAnalytics Stream Analytics job query

1. On the **TrafficAnalytics - Outputs** blade, under **Job topology**, click **Query**.
2. Add the following statements to the end of the existing query:

    ```SQL
    SELECT
      C.VehicleRegistration,C.LocationLatitude,C.LocationLongitude,C.Time
    INTO
      StolenCarAlerts
    FROM
      StolenVehicleFeed1 C
    JOIN
      StolenVehicleData V
    ON
      C.VehicleRegistration = V.Vehicle
    WHERE
      V.Recovered = ""

    SELECT
      C.VehicleRegistration,C.LocationLatitude,C.LocationLongitude,C.Time
    INTO
      StolenCarObservations
    FROM
      StolenVehicleFeed2 C
    JOIN
      StolenVehicleData V
    ON
      C.VehicleRegistration = V.Vehicle
    WHERE
      V.Recovered = ""
    ```

You can copy the preceding commands from the file **E:\\Labfiles\\Lab02\\ASAquery4.txt**.

3. Click **Save**, and then click **Yes**.

### Task 8: Start the TrafficAnalytics Stream Analytics job

1. On the **TrafficAnalytics - Query** blade, under **Configure**, click **Scale**.
2. On the **TrafficAnalytics - Scale** blade, in the **Streaming units** box, type **12**.
3. Click **Save**, and then click **Yes**.
4. On the **TrafficAnalytics - Scale** blade, click **Overview**, and then click **Start**.
5. On the **Start job** blade, click **Now**, and then click **Start**.
6. Wait until the job has successfully started before continuing with the lab.

### Task 9: Generate event hub data for processing with Stream Analytics

1. On the Start menu, type **Visual Studio**, and then press Enter.
2. On the **File** menu, point to **Open**, and then click **Project/Solution**.
3. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\SpeedCameraDevice** folder, click **SpeedCameraDevice.sln**, and then click **Open**. This is the same app that you used in Exercise 1, and it should already be configured to connect to your event hub.
4. Click **Start**. The app opens a console window displaying generated speed camera data that is being sent to the event hub.

### Task 10: Visualize Stream Analytics output using Power BI

1. In Internet Explorer, switch to the Power BI page.
2. Click **My Workspace**, and then click **DataSets**.
3. If the **Unsaved changes** dialog box appears, click **Don’t save**.
4. Verify that a streaming dataset named **StolenCarAlerts** is available (if this does not appear, wait a few minutes, and then refresh the page).
5. Click **+ Create**, and then click **Dashboard**.
6. In the **Create dashboard** dialog box, in the **Dashboard name** box, type **Stolen Vehicle Alerts**, and then click **Create**.
7. Click **+ Add tile**.
8. In the **Add tile** pane, click **Custom Streaming Data**, and then click **Next**.
9. In the **Add a custom streaming data tile** pane, click **StolenCarAlerts**, and then click **Next**.
10. In the **Add a custom streaming data tile** pane, in the **Visualization Type** list, click **Clustered column chart**.
11. Under **Axis**, click **Add value**, and then select **vehicleregistration**.
12. Under **Legend**, click **Add value**, and then select **time**.
13. Under **Value**, click **Add value**, and then select **locationlatitude**.
14. Under **Tooltips**, click **Add value**, and then select **locationlongitude**.
15. Under **Time window to display**, select **1 Seconds**, and then click **Next**.
16. In the **Tile details** pane, in the title box, type **Vehicles reported stolen and detected by cameras**, and then click **Apply**.
17. Leave the tile to display for a few minutes; note that it is updated every 1 seconds; it displays the registration number of a vehicle, together with the date, time, and location, if it is marked as stolen.
18. Hover the mouse over the chart, and verify that it shows vehicle registration, date/time, and location.

### Task 11: View Stream Analytics output in Data Lake Store

1. Switch to the Azure portal. 
2. Click **All resources**, and then click **adls_&lt;your name&gt;&lt;date&gt;_**.
3. On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **Data explorer**.
4. On the **adls&lt;_your name_&gt;&lt;_date_&gt; Data Lake Storage Gen1** blade, click **StolenCarObservations**, and then click through all the subfolders.
5. Click the log file to view the contents in File Preview. This file should contain one line for each stolen car observation. Verify that the data includes the fields you specified in your Azure Stream Analytics query.
6. Click **All resources**, and then click **TrafficAnalytics**.
7. On the **TrafficAnalytics** blade, click **Stop**, and then click **Yes**.
8. Switch to the Visual Studio app window (where the data is being generated), and press Enter to stop the app.

>**Result**: In this exercise, you uploaded data to a new Blob storage container, updated your event hub with new consumer groups, and reconfigured your TrafficAnalytics Azure Stream Analytics job to use these new inputs. You used Stream Analytics to process the event hubs data, and viewed the results in a Power BI dashboard, and in Data Lake Store.

## Exercise 5: Use multiple Stream Analytics jobs to process event hub, IoT hub and static file data, and output results using a Service Bus and custom application

### Task 1: Create a new Service Bus topic and add a subscription

1. In the Azure portal, click **All resources**, and then click **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
2. On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Entities**, click **Topics**, and then click **+ Topic**.
3. On the **Create topic Service Bus** blade, in the **Name** box, type **stolencaralerts**, and then click **Create**.
4. On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt; - Topics** blade, click **stolencaralerts**, and then click **+ Subscription**.
5. On the **Create subscription** blade, in the **Name** box, type **stolen**, and then click **Create**.

### Task 2: Reconfigure the IoT hub and add a new consumer group

1. Click **All resources**, and then click **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
2. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Settings**, click **Built-in endpoints**.
3. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt; - Built-in endpoints** blade, under **Consumer groups**, in the empty box at the end of the list, type **patrolcars4**.
4. Move the mouse to the next empty box to save the changes.

### Task 3: Reconfigure the event hub and add a new consumer group

1. Click **All resources**, and then click **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
2. On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Entities**, click **Event Hubs**, and then click **traffic**.
3. On the **traffic** blade, click **+ Consumer Group**.
4. On the **Create consumer group** blade, in the **Name** box, type **stolenvehiclefeed3**, and then click **Create**.

### Task 4: Reconfigure the TrafficAnalytics Azure Stream Analytics job inputs

1. Click **All resources**, and then click **TrafficAnalytics**.
2. On the **TrafficAnalytics** blade, under **Job topology**, click **Inputs**, click **+ Add stream input**, and then click **IoT Hub**.
3. On the **New input** blade, enter the following details:
    - **Input alias**: PatrolCarLocation
    - **Select IoT Hub from your subscriptions**: selected
    - **IoT Hub**: patrolcars&lt;_your name_&gt;&lt;_date_&gt;
    - **Consumer group**: patrolcars4
4. Leave all other settings at their defaults, and click **Save**.
5. Wait until the input has been successfully created before continuing with the lab.
6. On the **TrafficAnalytics - Inputs** blade, click **+ Add stream input**, and then click **Event Hub**.
7. On the **New input** blade, enter the following details:
    - **Input alias**: StolenVehicleFeed3
    - **Select Event Hub from your subscriptions**: selected
    - **Source**: Event hub
    - **Event Hub namespace**: camerafeeds&lt;_your name_&gt;&lt;_date_&gt;
    - **Event Hub name**: traffic
    - **Event Hub consumer group**: stolenvehiclefeed3
8. Leave all other settings at their defaults, and click **Save**.
9. Wait until the input has been successfully created before continuing with the lab.

### Task 5: Reconfigure the TrafficAnalytics Stream Analytics job outputs

1. On the **TrafficAnalytics - Inputs** blade, under **Job topology**, click **Outputs**, click **+ Add**, and then click **Service Bus topic**.
2. On the **Service Bus topic New output** blade, enter the following details:
    - **Output alias**: StolenVehicleAlerts
    - **Select topic from your subscriptions**: selected
    - **Service Bus namespace**: locationalerts&lt;_your name_&gt;&lt;_date_&gt;
    - **Topic name**: stolencaralerts
3. Leave all other settings at their defaults, and click **Save**.
4. Wait until the output has been successfully created before continuing with the lab.

### Task 6: Reconfigure the TrafficAnalytics Stream Analytics job query

1. On the **TrafficAnalytics - Outputs** blade, under **Job topology**, click **Query**.
2. Add the following statement to the end of the existing query:

    ```SQL
    SELECT
      P.CarID,V.Vehicle,C.LocationLatitude,C.LocationLongitude
    INTO
      StolenVehicleAlerts
    FROM
      StolenVehicleFeed3 C
    JOIN
      StolenVehicleData V
    ON
      C.VehicleRegistration = V.Vehicle
    JOIN
      PatrolCarLocation P
    ON
      ST_DISTANCE(CreatePoint(C.LocationLatitude,C.LocationLongitude),CreatePoint(P.LocationLatitude,P.LocationLongitude)) < 8000
    AND
      DATEDIFF(second,P,C) BETWEEN 0 AND 10
    WHERE
      V.Recovered = ""
    ```

You copy the preceding commands from **E:\\Labfiles\\Lab02\\ASAquery5.txt**.
2.  Click **Save**, and then click **Yes**.

### Task 7: Start the TrafficAnalytics Azure and PatrolCarAnalytics Stream Analytics jobs

1. On the **TrafficAnalytics - Query** blade, click **Overview**, and then click **Start**.
2. On the **Start job** blade, click **Now**, and then click **Start**.
3. Click **All resources**, and then click **PatrolCarAnalytics**.
4. On the **PatrolCarAnalytics** blade, click **Start**.
5. On the **Start job** blade, click **Now**, and then click **Start**.
6. Wait until the jobs have successfully started before continuing with the lab.

### Task 8: Generate event hub and IoT hub data for processing with Stream Analytics

1. Switch to the Visual Studio instance that has the **SpeedCameraDevice** project open.
2. Click **Start**. As before, the app opens a console window displaying generated speed camera data that is being sent to the event hub.
3. On the Start menu, type **Visual Studio**, and then press Enter, to start a new instance of Visual Studio.
4. On the **Get Started** page, click **Open Project / Solution**.
5. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\PatrolCarDevice2** folder, click **PatrolCarDevice.sln**, and then click **Open**. This is a modified version of the app you worked with in exercises 2 and 3.
6. In Solution Explorer, double-click **App.config**.
7. In App.config, in the **appSettings** section, in the **ServiceBusConnectionString** key, replace **YourServiceBusName** with **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**, and replace **YourServiceBusPrimaryKey** with the primary key you copied to **Config\_details.txt**.
8. In App.config, in the **appSettings** section, in the **IoTHubConnectionString** and **IotHubUri** keys, replace **YourNamespace** with **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
9. In the **IoTHubConnectionString** key, replace the SharedAccessKey value **YourIoTHubPrimaryKey** with the SharedAccessKey from the IoT hub connection string you copied to **Config\_details.txt**.
10. On the **Build** menu, click **Build Solution**. Verify that the app compiles successfully.
11. Click **Start**. The app opens a console window displaying the generated positions of patrol cars that are being sent to the IoT hub.

### Task 9: Start an application to receive Stream Analytics data using a Service Bus topic

1. On the Start menu, type **LocationAlerts**, and then press Enter. This action starts the application that displays a map showing the location of patrol cars, that you ran earlier.
2. Let the system run for a few minutes, to give it time to detect some stolen vehicles, and then observe the results. The **PatrolCarDevice** project reports messages when a patrol car is dispatched to chase a stolen vehicle. You should also see the location of the patrol car change to move towards the location reported for the stolen vehicle in the **LocationAlerts** app. Arrange your desktop so that you see the Patrol Car output and map side by side. If you do not see all the patrol cars, zoom out of the map.
3. At the end of the exercise, keep the apps and the Stream Analytics jobs running, ready for the final exercise in this lab.
4. Close Notepad, and save any changes.

>**Result**: In this exercise, you:
>
>- Created a new Service Bus topic, and added a subscription to this topic.
>- Reconfigured the IoT and event hubs, and added a new consumer group to each hub.
>- Reconfigured the TrafficAnalytics Azure Stream Analytics job to use these new inputs, and to use the new Service Bus topic as a job output.
>- Updated the job query to send data to the Service Bus topic, by using a Visual Studio application.

## Exercise 6: Use the Azure portal and Azure PowerShell to manage and scale Stream Analytics jobs

### Task 1: Add a monitoring alert to a Stream Analytics job

1. In the Azure portal, click **All resources**, and then click the **PatrolCarAnalytics**.
2. On the **PatrolCarAnalytics** blade, on the **Overview** page, scroll down to view the Monitoring graph. Note that, for this job, the number of input and output events are typically the same.
3. Click the **Resource utilization** graph.
4. On the **Metric** blade, click **View classis metrics**, and then click **+ Add metric alert (classic)**.
5. On the **Add rule** blade, in the **Name** box, type **Streaming unit utilization**.
6. In the **Metric** list, click **SU % Utilization**. Note the current range of utilization.
7. In the **Condition** list, click **Greater than**.
8. In the **Threshold** box, type **n**, where "n" is less than the maximum utilization you noted earlier; for example, if you noted a maximum of 50%, set the threshold to 40%.
9. Leave all the other settings at their defaults, and click **OK**.
10. Wait for 2 minutes.
11. Refresh the page in Internet Explorer, and then click the **Resource utilization** graph again.
12. Click **View classic metrics**.
13. Under **Available metrics**, select **SU % Utilization**.
14. Under the graph, click **View alerts for this resource (1 configured)**.
15. Verify that the status of the alert is set to **Warning**. This indicates that the alert has been triggered.
16. Close the **Alerts (classic)** blade.
17. Close the **Metrics (classic)** blade.
18. Close the **Metrics** blade.

### Task 2: Use the Azure portal to scale up a Stream Analytics job

1. On the **PatrolCarAnalytics** blade, click **Overview**, click **Stop**, and then click **Yes**.
2. Wait until the job has successfully stopped before continuing with the lab.
3. On the **PatrolCarAnalytics - Scale** blade, under **Configure**, click **Scale**.
4. On the **PatrolCarAnalytics - Scale** blade, drag the slider to **3**, click **Save**, and then click **Yes**.
5. On the **PatrolCarAnalytics - Scale** blade, click **Overview**, and then click **Start**.
6. On the **Start job** blade, click **Now**, and then click **Start**.
7. Wait until the job has successfully started before continuing with the lab.
8. On the **PatrolCarAnalytics** blade, wait for a couple of minutes, and then click the **Resource utilization** graph. Note that the **SU % Utilization** is lower than before, because more streaming units have been deployed.

### Task 3: Use Azure PowerShell to stop a Stream Analytics job

> **Note:** All the PowerShell commands shown in the exercise can be copied from the file **E:\\Labfiles\\Lab02\\ASAPowerShell.txt**.

1. On the desktop, close the **LocationAlerts** app, close the **PatrolCarDevice** app, and close the **SpeedCAmeraDevice** app.
2. On the Start menu, type **Windows PowerShell ISE**, right-click **Windows PowerShell ISE**, and then click **Run as administrator**.
3. In the **User Account Control** dialog box, click **Yes**.
4. In the script area, type the following commands, and then click **Run Script**:

    ``` PowerShell
    Login-AzureRmAccount
    Get-AzureRMStreamAnalyticsJob -NoExpand
    ```

5. In the **Sign in to your account** dialog box, enter the details of the Microsoft account that is associated with your Azure Learning Pass subscription, and then click **Sign in**.
6. The results display information about the two Stream Analytics jobs.
7. In the script area, type the following command, highlight it, and then click **Run Selection**:

    ``` PowerShell
    Stop-AzureRMStreamAnalyticsJob -ResourceGroupName CamerasRG –Name PatrolCarAnalytics
    ```

8. In the script area, type the following command, highlight it, and then click **Run Selection**:

    ``` PowerShell
    (Get-AzureRmStreamAnalyticsJob -ResourceGroupName CamerasRG -Name PatrolCarAnalytics).JobState
    ```

9. Verify that the job has stopped.
10. On the toolbar, click **Save**.
11. In the **Save As** dialog box, go to **E:\\Labfiles\\Lab02**, in the **File name** box, type **ShutdownASAjob.ps1**, and then click **Save**.

### Task 4: Use Azure PowerShell to scale down and restart a Stream Analytics job

1. In File Explorer, go to **E:\\Labfiles\\Lab02**, right-click **patrolcaranalytics.json**, point to **Open with**, and then click **Choose another app**.
2. In the **How do you want to open this file?** dialog box, click **More apps**, click **Microsoft Visual Studio Version Selector**, and then click **OK** to open the file in Visual Studio.
3. This file contains the JSON format code for the Stream Analytics job query, and the scaling information. Note the line near the end of the file that specifies the number of StreamingUnits to use (1).
4. Close patrolcaranalytics.json.
5. Switch to the PowerShell ISE.
6. On the toolbar, click **New**.
7. In the script area, type the following commands:

    ``` PowerShell
    New-AzureRmStreamAnalyticsTransformation -File E:\Labfiles\Lab02\patrolcaranalytics.json -JobName PatrolCarAnalytics -ResourceGroupName CamerasRG -Name Transformation -Force

    Start-AzureRMStreamAnalyticsJob -ResourceGroupName CamerasRG –Name PatrolCarAnalytics

    (Get-AzureRmStreamAnalyticsJob -ResourceGroupName CamerasRG -Name PatrolCarAnalytics).JobState
    ```

8. On the toolbar, click **Save**.
9. In the **Save As** dialog box, go to **E:\\Labfiles\\Lab02**, in the **File name** box, type **ScaleUpAndStartASAjob.ps1**, and then click **Save**.
10. On the toolbar, click **Run Script**.
11. Wait for the script to run; this might take several minutes.
12. Switch to the Azure portal.
13. On the **PatrolCarAnalytics** blade, under **Configure**, click **Scale**.
14. On the **Scale** blade, verify that the job has been restarted and the number of streaming units has been reset to 1.

### Task 5: Use job diagrams to visualize Stream Analytics job configurations

1. In the Azure portal, on the **PatrolCarAnalytics - Scale** blade, under **Support + troubleshooting**, click **Job diagram**.
2. Note the inputs from the IoT hub, the queries, and the outputs to the Service Bus queue, Data Lake Store, and Power BI.
3. Click any of the boxes to view the statistics for that item.
4. Close the job diagram.
5. Click **All resources**, and then click **TrafficAnalytics**.
6. In the Azure portal, on the **TrafficAnalytics - Stream Analytics job** blade, under **Support + troubleshooting**, click **Job diagram**.
7. Examine the diagram. Note that, for this job, the diagram is more complex because there are more inputs, outputs, and queries, including data merging.
8. Close the job diagram.

### Task 6:  Lab closedown

1. On the **TrafficAnalytics** blade, click **Overview**, click **Stop**, and then click **Yes**.
2. Click **All resources**, and then click **PatrolCarAnalytics**.
3. On the **PatrolCarAnalytics** blade, click **Stop**, and then click **Yes**.
4. Close the PowerShell ISE.
5. Close all instances of Visual Studio.
6. Do not remove the Azure resources (resource group, Stream Analytics jobs, event hub, IoT hub, and storage); these resources will be used in Lab 3.

>**Result**: In this exercise, you:

- Added a monitoring alert to a Stream Analytics job.
- Used the Azure portal to scale up a Stream Analytics job.
- Used Azure PowerShell to stop a Stream Analytics job.
- Used Azure PowerShell to scale down and restart a Stream Analytics job.
- Used job diagrams to visualize Stream Analytics job configurations.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
