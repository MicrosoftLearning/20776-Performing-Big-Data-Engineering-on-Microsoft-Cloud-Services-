# Module 6: Implementing Custom Operations and Monitoring Performance in Azure Data Lake Analytics

- [Module 6: Implementing Custom Operations and Monitoring Performance in Azure Data Lake Analytics](#module-6-implementing-custom-operations-and-monitoring-performance-in-azure-data-lake-analytics)
    - [Lab: Implementing custom operations and monitoring performance in Azure Data Lake Analytics](#lab-implementing-custom-operations-and-monitoring-performance-in-azure-data-lake-analytics)
    - [Exercise 1: Use a custom extractor, read JSON file data, and use a custom outputter to XML](#exercise-1-use-a-custom-extractor-read-json-file-data-and-use-a-custom-outputter-to-xml)
        - [Task 1: Deploy and test a JSON extractor](#task-1-deploy-and-test-a-json-extractor)
        - [Task 2: Deploy and test an XML outputter](#task-2-deploy-and-test-an-xml-outputter)
    - [Exercise 2: Optimize a table in the ADLA catalog](#exercise-2-optimize-a-table-in-the-adla-catalog)
        - [Task 1: Create the SpeedData table in the catalog](#task-1-create-the-speeddata-table-in-the-catalog)
        - [Task 2: Create a U-SQL job that analyzes the data for a specific camera](#task-2-create-a-u-sql-job-that-analyzes-the-data-for-a-specific-camera)
        - [Task 3: Redistribute the data to optimize data retrieval](#task-3-redistribute-the-data-to-optimize-data-retrieval)
    - [Exercise 3: Implement a custom processor in ADLA](#exercise-3-implement-a-custom-processor-in-adla)
        - [Task 1: Preparation: upload stolen vehicle data to ADLS (using AzCopy and Adlcopy)](#task-1-preparation-upload-stolen-vehicle-data-to-adls-using-azcopy-and-adlcopy)
        - [Task 2: Examine and deploy a custom reducer](#task-2-examine-and-deploy-a-custom-reducer)
        - [Task 3: Test the custom reducer](#task-3-test-the-custom-reducer)
        - [Task 4: Analyze the speed camera data to check for stolen vehicles](#task-4-analyze-the-speed-camera-data-to-check-for-stolen-vehicles)
    - [Exercise 4: Use existing analytics, developed in R, in an ADLA solution](#exercise-4-use-existing-analytics-developed-in-r-in-an-adla-solution)
        - [Task 1: Determining correlations by using R](#task-1-determining-correlations-by-using-r)

## Lab: Implementing custom operations and monitoring performance in Azure Data Lake Analytics

If you haven't completed lab 5, perform the following steps to create a Data Lake Storage Account and an ADLA account:

1. In Internet Explorer, go to http://portal.azure.com, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
2. In the Azure portal, click **+ Create a resource**, click **Storage**, and then click **Data Lake Storage Gen1**.
3. On the **New Data Lake Storage Gen1** blade, in the **Name** box, type **adls&lt;_your name_&gt;&lt;_date_&gt;**.
4. Under **Resource group**, click **Create new**, and type **CamerasRG**.
5. In the **Location** list, select your nearest location from the currently available Data Lake Store regions.
6. Leave all other settings at their defaults, and click **Create**.
7. Click **+ Create a resource**, click **Analytics**, and then click **Data Lake Analytics**.
8. On the **New Data Lake Analytics account** blade, in the **Name** box, type **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
9. Under **Resource Group**, click **Use existing**, and then click **CamerasRG**.
10. In the **Location** list, select the same location as you used for your Data Lake Store.
11. Click **Data Lake Storage Gen1 Configure required settings**.
12. On the **Select Data Lake Store** blade, click **adls&lt;_your name_&gt;&lt;_date_&gt;**.
13. Leave all other settings at their defaults, and click **Create**.
14. Wait until the storage has deployed before continuing with the lab.

## Exercise 1: Use a custom extractor, read JSON file data, and use a custom outputter to XML

### Task 1: Deploy and test a JSON extractor

1. Using **File Explorer**, go to the **E:\\Labfiles\\Lab06\\Exercise1** folder, right-click **SpeedData.zip**, and then click **Extract All**.
2. In the **Extract Compressed (Zipped) Folders** dialog box, in the **Files will be extracted to this folder** box, type **E:\\Labfiles\\Lab06\\Exercise1**, and then click **Extract**. 
3. Verify that the file **SppedData.json** is extracted. This file contains the speed camera data used by this exercise.
4. On the the Windows **Start** menu, type **Visual Studio 2017**, and then press Enter.
5. In Visual Studio, on the **File** menu, click **Open**, and then click **Project/Solution**.
6. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab06\\Exercise1\\Starter\\CustomFunctions** folder, click **CustomFunctions.sln**, and then click **Open**.
7. In **Solution Explorer**, expand the **CustomExtractors** project, and then double-click **JsonExtractor.cs**.
8. In the code editor window, browse the code for the JsonExtractor, and note the following points:
    - The JsonExtractor class extends the IExtractor base class.
    - The Extract function is an override; this override uses functions in the Newtonsoft JSON library to read the JSON data from the input line (this contains a single line from the input file).
    - After the JSON data has been retrieved, and the fields in the input line extracted into an output row, this output row is returned to USQL.
    - The class is tagged with the [SqlUserDefinedExtractor(AtomicFileProcessing = true)] attribute; this is because the input data consists of a single object (a JSON array), and so its contents cannot be read by separate vertices in parallel.
    - The constructor specifies the name of the array to parse in the input; this is because there could possibly be multiple arrays in the same JSON file.
    - This class contains many other supporting functions that do all the parsing, and so on; you can ignore these functions for the purposes of this exercise.
9. On the **Build** menu, click **Build Solution**.
10. In **Solution Explorer**, right-click the **CustomExtractors** project, and then click **Register Assembly**.
11. In the **Assembly Registration** dialog box, set the **ADLA Account** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.

    > **Note**: If you can only see local resources in the **Assembly Regisration** dialog box, perform the following steps:
    >
    > 1. On the **File** menu, click **Account Settings** and sign in as the account associated with your Azure subscription. If necessary, click **Add an account**.
    > 2. On the **View** menu, click **Cloud Explorer**, click **Azure Account Settings**, and add the subscription for your Azure account.
    
12. Leave the **Database** set to **master**.
13. Select the **Replace assembly if it already exists** check box.
14. Expand **Managed Dependencies**, select the **Newtonsoft.Json** check box (this is the assembly containing the JSON Newtonsoft library), and then click **Submit**.
15. If the **Registration Script** dialog box appears, click **Yes**.
16. On the Windows **Start** menu, type **Wordpad**, and then press Enter.
17. In Wordpad, on the **File** menu, click **Open**.
18. In the **Open File** dialog box, go to the folder **E:\\Labfiles\\Lab06\\Exercise1**, click **All Documents (\*.\*)**, click **SpeedData.json**, and then click **Open**.
19. Browse the data in the first few rows of the SpeedData.json file. This file contains speed camera data formatted as a JSON array; it represents a JSON array as written by the ASA jobs from earlier labs. There are more than a million records in the file.
20. Close Wordpad.
21. Switch to the Azure portal.
22. Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data explorer**.
23. In the Data explorer blade, in the default (root) folder, click **Upload**.
24. In the **Upload files** blade, click the **Select a file** button.
25. In the **Open** dialog box, go to the **E:\\Labfiles\\Lab06\\Exercise1** folder, click **SpeedData.json**, and then click **Open**.
26. On the **Upload files** blade, click **Add selected files**. The upload will take a few minutes.
27. After the file has uploaded, close the **Upload files** blade.
28. On the Windows **Start** menu, type **Visual Studio 2017**, and then press Enter, to open a second instance of Visual Studio 2017.
29. In Visual Studio, on the **File** menu, click **New**, and then click **Project**.
30. In the **New Project** dialog box, in the **Templates** list, expand **Azure Data Lake**, and then click **U-SQL Project**.
31. In the **New Project** dialog box, in the **Name** box, type **JsonExtractorTest**, and then click **OK**.
32. In the **Script.usql** pane, type the following code. You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise1\\JsonExtractorTest1.usql**:

    ```SQL
    // Assembly references for the JSON extractor and Newtonsoft assembly (required by the extractor stored in the catalog

    REFERENCE ASSEMBLY [Newtonsoft.Json];
    REFERENCE ASSEMBLY [CustomExtractors];

    // Use the Json extractor to read the data from the SpeedData.json file. The fields of interest in the file are CameraID string, SpeedLimit int, Speed int, VehicleRegistration string, Date string (there is also the Month field that you can ignore for this lab):

    @speedData =
    EXTRACT CameraID string, SpeedLimit int, Speed int, VehicleRegistration string, Date string
    FROM "/SpeedData.json"
    USING new CustomExtractors.JsonExtractor();

    // Save the data to a CSV file named ConvertedSpeedData.csv:

    OUTPUT @speedData
    TO "/ConvertedSpeedData.csv"
    USING Outputters.Csv(quoting: false, outputHeader: true);
    ```

33. In the **Script.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set **Database** to **master**, and then click **Submit**.
34. When the job has completed, close the **Job View** pane.
35. Switch to the Azure portal.
36. In the **Data explorer** blade, click **ConvertedSpeedData.csv**, to view the extracted data in CSV format.
37. Close the **File Preview** blade.

### Task 2: Deploy and test an XML outputter

1. Switch to the instance of Visual Studio 2017 that has the **CustomFunctions** solution open.
2. In Solution Explorer, expand the **CustomOutputters** project, and then double-click **XmlOutputter.cs**.
3. In the code editor window, note the following points:
    - The XmlOutputter class extends the IOutputter abstract base class.
    - The Output function is an override that formats a line of data as a simple XML object; the object tag to use is specified by the constructor.
    - The class is tagged with the [SqlUserDefinedOutputter(AtomicFileProcessing = false)] attribute; each line of output is a separate XML document, so the output is generated by using multiple vertices running in parallel.
    - The Close method flushes and closes the output stream.
4. On the **Build** menu, click **Rebuild Solution**.
5. In Solution Explorer, right-click **CustomOutputters**, and then click **Register Assembly**.

    > **Note:** If the **Register Assembly** option does not appear for thie project, perform the following steps:
    >
    > 1. Right-click the **CustomExtractors** project and then click **Register Assembly**.
    > 2. In the **Assembly Registration** dialog bix, click the ellipsis button by the **Load assembly from path** box.
    > 3. In the **Load Assembly** dialog box, browse the **E:\Labfiles\Lab06\Exercise1\Starter\CustomFunctions\CustomOutputters\bin\Debug** folder, click **CustomOutputters.dll**, and then click **Open**.
    > 4. Click **OK*.
    
6. In the **Assembly Registration** dialog box, set the **ADLA Account** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, leave the **Database** set to **master**, select the **Replace assembly if it already exists** check box, and then click **Submit**.
7. Switch to the instance of Visual Studio 2017 that has the **JsonExtractorTest** solution open.
8. In the **Script.usql** script, add the following statements to the end of the script:

    ```SQL
    // Assembly reference for the XML outputter

    REFERENCE ASSEMBLY [CustomOutputters];

    // Modify the statement that outputs the data to use the XmlOutputter. Save the data as ConvertedSpeedData.xml

    OUTPUT @speedData
    TO "/ConvertedSpeedData.xml"
    USING new CustomOutputters.XmlOutputter();
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise1\\JsonExtractorTest2.usql**.

9. In the **Script.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **master**, and then click **Submit**.
10. When the job has completed, close the **Job View** pane.
11. Switch to the Azure portal.
12. In the Data explorer blade for the **speedsdla&lt;_your name_&gt;&lt;_date_&gt;** account, next to **ConvertedSpeedData.xml**, click the ellipsis (**...**), and then click **Download**.
13. On the **Download** blade, click **Start Download now**.
14. In the Internet Explorer message box, click the **Save** drop-down arrow, and then click **Save as**.
15. In the **Save As** dialog box, go to the folder **E:\\Labfiles\\Lab06\\Exercise1**, and then click **Save**. It will take a couple of minutes to download the file.
16. In the Internet Explorer message box, click **Open folder**.
17. In File Explorer, double-click **ConvertedSpeedData.xml**.
18. In the **How do you want to open this file?** dialog box, click **Microsoft Visual Studio 2017**, and then click **OK**.
19. Confirm that the file contains the speed camera data formatted as XML.
20. Close the instance of Visual Studio that has the open **ConvertedSpeedData.xml** window.
21. Switch to the Azure portal.
22. Close the **Download** blade.
23. Close all instances of Visual Studio.

    > **Note**: If you try to view the data using Data Explorer, the data will not be displayed correctly because Data Explorer does not understand the XML format.

>**Result**: In this exercise, you  deployed and tested a custom extractor, and a custom outputter.

## Exercise 2: Optimize a table in the ADLA catalog

### Task 1: Create the SpeedData table in the catalog

1. On the Windows **Start** menu, type **Visual Studio 2017**, and then press Enter.
2. On the **File** menu, click **New**, and then click **Project**.
3. In the **New Project** dialog box, in the **Templates** list, expand **Azure Data Lake**, and then click **U-SQL**.
4. In the **New Project** dialog box, in the **Name** box, type **SpeedCameraAnalytics2**, and then click **OK**.
5. In Solution Explorer, right-click **Script.usql**, click **Rename**, type **CreateTable**, and then press Enter.
6. In the **CreateTable.usql** pane, add the following statement to create a new database called VehicleData if it doesn't already exist:

    ```SQL
    CREATE DATABASE IF NOT EXISTS VehicleData;
    ```

    You can copy the SQL code for thie task from the file **E:\\Labfiles\\Lab06\\Exercise2\\CreateTable1.usql**.

7. In the **CreateTable.usql** pane, add the following statements to create a table for holding speed camera information, and to index the data by camera id, and hash the data by the vehicle registration:

    ```SQL
    DROP TABLE IF EXISTS VehicleData.dbo.SpeedCameraData;
    CREATE TABLE VehicleData.dbo.SpeedCameraData(
        CameraID string,
        VehicleRegistration string,
        Speed int,
        SpeedLimit int,
        Date DateTime,
        INDEX cameraidx
        CLUSTERED(CameraID ASC)
        DISTRIBUTED BY
        HASH(VehicleRegistration)
    );
    ```

    The rationale behind this hashing strategy is to distribute the load across the database, to try and avoid hotspots in the data. The index is intended to support fast lookup of speed data by camera ID.

8. In the **CreateTable.usql** pane, add the following statements to reference the assemblies required by the JSON extractor:

    ```SQL
    REFERENCE ASSEMBLY [Newtonsoft.Json];
    REFERENCE ASSEMBLY [CustomExtractors];
    ```

9. In the **CreateTable.usql** pane, add the following statements to read the data from the SpeedData.json file:

    ```SQL
    @speedData =
    EXTRACT CameraID string, SpeedLimit int, Speed int, VehicleRegistration string, Date string
    FROM "/SpeedData.json"
    USING new CustomExtractors.JsonExtractor();
    ```

    The dates in the JSON input are strings in the format "dd/mm/yy hh24:mi". You need to add a user-defined function to convert a string in this format into a DateTime object.

10. In Solution Explorer, expand **CreateTable.usql**, and then double-click **CreateTable.usql.cs**, to edit the code-behind C# file.
11. Replace the entire contents of this file with the following code:

    ```C#
    using System;
    namespace SpeedCameraAnalytics2
    {
        public class UDFs
        {
            public static DateTime ConvertStringToDate(string date)
            {
                // The input string is in the form "dd/mm/yyyy hh24:mi"
                char[] delimiters = { ' ', '/', ':' };
                string[] dateBits = date.Split(delimiters);
                int day = Convert.ToInt32(dateBits[0]);
                int month = Convert.ToInt32(dateBits[1]);
                int year = Convert.ToInt32(dateBits[2]);
                int hour = Convert.ToInt32(dateBits[3]);
                int minute = Convert.ToInt32(dateBits[4]);
                DateTime dt = new DateTime(year, month, day, hour, minute, 0);
                return dt;
            }
        }
    }
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise2\\CreateTable2.usql**. This statement inserts the data read by using the JSON extractor into the SpeedCameraData table; notice that this statement calls the ConvertStringToDate function for each row of input.

12. In Solution Explorer, double-click **CreateTable.usql**, and then add the following statement to the end of the existing code:

    ```SQL
    INSERT INTO VehicleData.dbo.SpeedCameraData (CameraID, VehicleRegistration, Speed, SpeedLimit, Date)
    SELECT CameraID, VehicleRegistration, Speed, SpeedLimit, SpeedCameraAnalytics2.UDFs.ConvertStringToDate(Date) AS Date
    FROM @speedData;
    ```

    This statement inserts the data read by using the JSON extractor into the SpeedCameraData table; notice that this statement calls the ConvertStringToDate function for each row of input.

13. In the **CreateTable.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **master**, and then click **Submit**.
14. Wait for the job to complete.
15. Switch to the Azure portal.
16. Click **All resources**, and then click **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
17. On the **speedsdla&lt;_your name_&gt;&lt;_date_&gt;** blade, under **DATA LAKE ANALYTICS**, click **Job management**.
18. On the **speedsdla&lt;_your name_&gt;&lt;_date_&gt; - Job management** blade, click the topmost job This job should be named **CreateTable**. 
19. Verify that the status of the job is **Succeeded** (if the status is Preparing, Queued, or Running, wait for the job to complete before continuing).
20. At the bottom of the graph, click the **SpeedCameraData** table.
21. On the **dbo.SpeedCameraData** blade, click **Query Table**.
22. On the **New U-SQL Job** blade, click **Submit Job**.
23. Wait while the query job runs. When it has completed, click the **VehicleData.dbo.SpeedCameraData.tsv** file.
24. Browse the data. You should see rows for Camera 0 (the browser only shows the first few rows), and the data is not in any specific order.
25. Close the **File preview** blade.

### Task 2: Create a U-SQL job that analyzes the data for a specific camera

1. Switch to Visual Studio.
2. Close any existing **Job View** panes.
3. In Solution Explorer, right-click **SpeedCameraAnalytics2**, click **Add**, and then click **New Item**.
4. In the **Add New Item - SpeedCameraAnalytics2** dialog box, click **U-SQL Script**, in the **Name** box, type **AnalyzeSpeedsByCamera.usql**, and then click **Add**.
5. In AnalyzeSpeedsByCamera.usql, add the following statements to perform a query and generate a summary for Camera 121:

    ```SQL
    // Find the statistics for a specific camera

    DECLARE @camera = "Camera 121";

    @speedSummary =
        SELECT CameraID,
            MAX(SpeedLimit) AS SpeedLimit,
            COUNT(*) AS NumberOfObservations,
            MIN(Speed) AS Lowest,
            MAX(Speed) AS Highest,
            AVG(Speed) AS Average
        FROM VehicleData.dbo.SpeedCameraData
        WHERE CameraID == @camera
        GROUP BY CameraID;

    // Save the results to SpeedSummary.csv::

    OUTPUT @speedSummary
    TO "/SpeedSummary.csv"
    USING Outputters.Csv(outputHeader: true, quoting: false);
    ```

     You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise2\\AnalyzeSpeedsByCamera.usql**.

6. In the **AnalyzeSpeedsByCamera.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **VehicleData**, and then click **Submit**. Wait for the job to complete.
7. In the **Job View** pane, position the cursor over the **SV1 Extract** stage; this stage should report that it ran 10 vertices, read nearly 40 MB of data, and output 10 rows (there is one row of summary data generated by each vertex). These 10 rows were passed to the SV2 Aggregate stage, which combined them together to produce a single row.
8. In the **Job View** pane, double-click **SpeedSummary.csv**. It should contain the following results:

    ```Text
    CameraID: Camera 121
    SpeedLimit: 30
    Number of Observations: 6057
    Lowest: 0
    Highest: 116
    Average: 7
    ```

9. Close the **File Preview** pane.
10. In the **Job View** pane, click **Load Profile**.
11. Right-click **SV1 Extract**, and then click **Show Vertex Execution View**. The job was run with the default number of AUs (5), and you can see how the job was performed, with five vertices running first, and the next five running as the first five completed. The vertex for the Aggregate stage ran when the vertices for the Extract stage had all finished.
12. In the upper left of the **Vertex Execution View**, click the left arrow to return to the **Job View** pane.
13. Right-click **SV1 Extract**, and then click **Show Stage Scatter View**.
14. In the **Stage Scatter Chart**, under **Legend**, clear the **Output** check box, to focus on the volume of data and time spent performing input. Each vertex read approximately the same amount of data (about 4 MB), but the time spent is grouped into two distinct sets. This is because the second five vertices had to wait for a vertex to become available while the first five were running.
15. In the upper left of the **Stage Scatter Chart**, click the left arrow to return to the **Job View** pane.
16. Right-click **SV1 Extract**, and then click **Show Vertex Operator View**. This view shows the logical data flow in terms of fields and numbers of rows. The extractor read 6,057 rows but, because the data is spread across the database, it created a separate vertex to handle the rows from each chunk of data that it read. Each vertex (Process\_1 in the graph) performs the aggregation over the data from that chunk, and sends the results to the second stage (Process\_2). Process\_2 does the final aggregation and sends the results to the output.
17. Close the **View** **Vertex** and **Job View** panes.

### Task 3: Redistribute the data to optimize data retrieval

One way to optimize the data would be to partition it by camera ID. However, there are currently 500 cameras in this dataset, so this process would involve creating 500 partitions, which is probably not feasible (note that U-SQL only supports partitioning by ID, and does not support user-defined partitioning functions that are available in SQL Server). Another solution is to distribute the data by Camera ID rather than VehicleRegistration. In this way, the observations for a specific camera should be grouped close together in the database, and will hopefully reduce the amount of I/O that the analysis needs to perform.

1. In Visual Studio, click the **CreateTable.usql** pane.
2. In the **CreateTable.usql** script, edit the CREATE TABLE command to distribute data by hashing the CameraID. Replace the existing DISTRIBUTED BY HASH(VehicleRegistration) string with the following text:

    ```SQL
    DISTRIBUTED BY
    HASH(CameraID)
    ```

3. In the **CreateTable.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **master**, and then click **Submit**.
4. Wait until the script has completed successfully before continuing with this exercise.
5. Click the **AnalyzeSpeedsByCamera.usql** pane.
6. In the **AnalyzeSpeedsByCamera.usql** pane, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **VehicleData**, and then click **Submit**.
7. When the script has completed, examine the graph in the **Job View** pane. Click the **SV1 Extract** stage. You should now see that the job comprised a single stage that required only a single vertex. This stage read 3.93 MB of data (rather than 10 stages each reading nearly 4 MB each) and, because the data was all available in the same "chunk", it could be processed and aggregated in a single stage.
8. Double-click the **SpeedSummary.csv** file and verify that the results are the same as before:

    ```Text
    CameraID: Camera 121
    SpeedLimit: 30
    Number of Observations: 6057
    Lowest: 0
    Highest: 116
    Average: 7
    ```

9. Leave Visual Studio open. You will use this project in the next exercise.

>**Result**: In this exercise, you created a table in the ADLA catalog, analyzed data in this table, and redistributed the data in the catalog to optimize retrieval.

## Exercise 3: Implement a custom processor in ADLA

### Task 1: Preparation: upload stolen vehicle data to ADLS (using AzCopy and Adlcopy)

1. In the Azure portal, click **+ Create a resource**, click **Storage**, and then click **Storage account - blob, file, table, queue**.
2. On the **Create storage account** blade, by **Resource group**, click **Use existing**, and then click **CamerasRG**.
3. In the **Name** box, type **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**.
4. In the **Location** list, select the same location as you used for your ADLA account.
5. In the **Account kind** list, click **Blob storage**.
6. Leave all other details at their defaults, and click **Review + create**, and then click **Create**.
7. Wait until the storage account has been successfully created before continuing with the exercise.
8. Click **All resources**, and then click **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**.
9. On the **vehicledata&lt;_your name_&gt;&lt;_date_&gt;** blade, under **BLOB SERVICE**, click **Blobs**, and then click **+ Container**.
10. In the **New container** dialog box, in the **Name** box, type **stolen**, and then click **OK**.
11. On the **vehicledata&lt;_your name_&gt;&lt;_date_&gt; -** **Containers** blade, under **SETTINGS**, click **Access keys**.
12. Next to **key1**, click the **Click to copy** button, to copy the key to the clipboard.
13. On the desktop, right-click the Windows **Start** button, and then click **Command Prompt (Admin)**.
14. In the **User Account Control** dialog box, click **Yes**.
15. At the command prompt, type the following command, and then press Enter:

    ```CMD
    dir E:\Labfiles\Lab06\Exercise3\StolenVehicles /s
    ```

    Note that the **StolenVehicles** folder contains eight years of stolen vehicle data, organized in subfolders by year/month/day; there are 2,914 separate CSV files.

16. At the command prompt, type the following command. Replace **&lt;storage account name&gt;** with **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**, and replace **&lt;storage key&gt;** with the key you copied to the clipboard, and then press Enter:

    ```CMD
    azcopy /Source:"E:\Labfiles\Lab06\Exercise3\StolenVehicles" /Dest:https://<storage account name>.blob.core.windows.net/stolen /DestKey:<storage key> /S
    ```

    The copy process might take several minutes to complete. Wait until all files have been copied before continuing with the exercise.

17. On the Windows **Start** menu, type **Visual Studio 2017**, and then press Enter. This action starts a new instance of Visual Studio.
18. In Visual Studio, on the **View** menu, click **Cloud Explorer**.
19. In **Cloud Explorer**, if the account associated with Azure Learning Pass subscription is not listed, complete the following steps:
    1. Click the **Azure** **Account settings** icon, and then click **Add an account**.
    2. In the **Sign in to your account** dialog box, sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
    3. In Cloud Explorer, select your Azure Learning Pass subscription, and then click **Apply**.
20. Under your Azure Learning Pass subscription folder, expand **Storage Accounts**, expand **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**, expand **Blob Containers**, and then double-click **stolen**.
21. Verify that the files and subfolders have been uploaded.
22. Close Visual Studio.
23. Switch to the Azure portal.
24. Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data explorer**.
25. In the Data explorer blade, click **New Folder**.
26. In the **Create new folder** box, type **Stolen**, and then click **OK**.
27. Switch to the command prompt.
28. At the command prompt, type the following command. Replace **&lt;storage account name&gt;** with **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**, replace **&lt;Data Lake Store name&gt;** with **adls&lt;_your name_&gt;&lt;_date_&gt;**, and replace **&lt;storage key&gt;** with the blob store key you copied to the clipboard), and then press Enter:

    ```CMD
    adlcopy /source https://<storage account name>.blob.core.windows.net/stolen/ /dest adl://<Data Lake Store name>.azuredatalakestore.net/Stolen/ /sourcekey <storage key>
    ```

29. If a **Sign in to your account** dialog box appears, sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.

    > **Note**: Depending on the region and the location of the Blob storage account (ideally they should be in the same region, but might not be), AdlCopy will take from two to 20 minutes to copy the data. Ignore the stats that indicate the percentage of files copied—it sits at 0.00 percent until complete then jumps to 100 percent, and might copy the data in three phases (files 1 to 1,000, then files 1,001 to 2,000, and then the remainder).

30. Switch to the Azure portal.
31. In the Data explorer blade, click the **Stolen** folder, and verify that all the files and folders have been copied across to this folder.

### Task 2: Examine and deploy a custom reducer

1. On the desktop, on the Windows **Start** menu, type **Visual Studio 2017**, and then press Enter
2. In Visual Studio, on the **File** menu, click **Open**, and then click **Project/Solution**.
3. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab06\\Exercise3\\Starter\\CustomReducers** folder, click **CustomReducers.sln**, and then click **Open**.
4. In Solution Explorer, expand **CustomReducers**, and then double-click **StolenVehicleReducer.cs**.
5. In the code editor window, browse the code for the StolenVehicleReducer; note the following points:
    - The ReduceByRecoveredVehicles class extends the IReducer base class.
    - The class is tagged with the [SqlUserDefinedReducer(IsRecursive = true)] attribute; you can reduce each group of data in parallel.
    - The Reduce function is an override that examines each row of input; the input contains a set of stolen vehicle records (VehicleRegistration, DateStolen, DateRecovered) that will be grouped by registration (you will specify this when you call the reducer from the U-SQL job).
    - The Reduce function only outputs rows for vehicles that it considers to be still missing (the most recent record does not have a recovery date).
6. On the **Build** menu, click **Build Solution**.
7. In Solution Explorer, right-click **CustomReducers**, and then click **Register Assembly**.
8. In the **Assembly Registration** dialog box, set the **ADLA** **Account** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
9. Leave the **Database** set to **master**.
10. Select the **Replace assembly if it already exists** check box, and then click **Submit**.
11. When the **Assembly Registration** job has completed, close the **Job View** pane.

### Task 3: Test the custom reducer

1. Switch to the instance of Visual Studio 2017 that has the **SpeedCameraAnalytics2** solution open.
2. In Solution Explorer, right-click **SpeedCameraAnalytics2**, point to **Add**, and then click **New Item**.
3. In the **Add New Item** dialog box, click **U-SQL Script**, in the **Name** box, type **AnalyzeSpeedsByVehicle.usql**, and then click **Add**.
4. In the **AnalyzeSpeedsByVehicle.usql** pane, add the following statements:

    ```SQL
    // Assembly references for the reducer:

    REFERENCE ASSEMBLY CustomReducers;

    // Use a CSV extractor to read the stolen vehicle data from the files under the Stolen folder in ADLS file; the fields of interest in the file are VehicleRegistration string, DateStolen string, and DateRecovered string:

    @stolenVehicleHistory =
    EXTRACT VehicleRegistration string,
    DateStolen string,
    DateRecovered string // Can be empty
    FROM "/Stolen/{*}/{*}/{*}/VehicleData.csv"
    USING Extractors.Csv(skipFirstNRows: 1);

    // Call the reducer to reduce the rowset to only those vehicles that are currently marked as stolen; group the data by VehicleRegistration as it is passed to the reducer:

    @stolenVehicles =
    REDUCE @stolenVehicleHistory
    ON VehicleRegistration
    PRODUCE VehicleRegistration string,
    DateStolen DateTime
    USING new CustomReducers.ReduceByRecoveredVehicles();

    // Save the results to StolenVehicleSpeedAnalysis.csv:

    OUTPUT @stolenVehicles
    TO "/StolenVehicleSpeedAnalysis.csv"
    USING Outputters.Csv(quoting : false, outputHeader : true);
    ```

     You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle1.usql**.

5. In the **AnalyzeSpeedsByVehicle.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **master**, and then click **Submit**.
6. When the job has completed, close the **Job View** pane.
7. Switch to the Azure portal.
8. Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data explorer**.
9. In the Data explorer blade, in the lower right of the blade, click the **Next** arrow, and then click **StolenVehicleSpeedAnalysis.csv**. Note that the data is sorted by VehicleRegistration as a by-product of the reduction process.
10. On the **File Preview** blade, click **Download**.
11. On the **Download** blade, click **Start Download now**.
12. In the Internet Explorer message box, click the **Save** drop-down arrow, and then click **Save as**.
13. In the **Save As** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise3**, and then click **Save**.
14. In the Internet Explorer message box, click **Open folder**.
15. In File Explorer, double-click **StolenVehicleSpeedAnalysis.csv**.
16. In Microsoft Excel, view the data, and note that there are 241,244 records, plus the header.
17. Close Microsoft Excel.
18. Switch to the Azure portal.
19. Close the **Download** and **File Preview** blades.

### Task 4: Analyze the speed camera data to check for stolen vehicles

1. Return to the instance of Visual Studio 2017 that has the **SpeedCameraAnalytics2** solution open.
2. In the **AnalyzeSpeedsByVehicle.usql** script, before the OUTPUT statement, add the following SELECT statement to join the data in the **VehicleData.dbo.SpeedCameraData** table in the catalog with the stolen vehicle data returned by the reducer across the VehicleRegistration column. Count the number of rows for each camera:

    ```SQL
    @stolenVehicleAnalysis =
        SELECT 
            C.CameraID,
            COUNT(C.VehicleRegistration) AS NumStolenVehicles
        FROM
            VehicleData.dbo.SpeedCameraData AS C
        JOIN
            @stolenVehicles AS V
        ON
            C.VehicleRegistration == V.VehicleRegistration
        GROUP BY
            C.CameraID;
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle2.usql**.

3. In the **AnalyzeSpeedsByVehicle.usql** script, before the OUTPUT statement, add another SELECT statement that simply finds the total number of vehicles that have passed each camera:

    ```SQL
    @vehicleAnalysis =
        SELECT
            CameraID,
            COUNT(VehicleRegistration) AS NumVehicles
        FROM
            VehicleData.dbo.SpeedCameraData
        GROUP BY
            CameraID;
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle3.usql**.

4. In **AnalyzeSpeedsByVehicle.usql** script , before the OUTPUT statement, join the results of the previous two SELECT statements across the CameraID column, and calculate the percentage of cars passing each camera that are stolen:

    ```SQL
    @speedCameraAnalysis =
        SELECT
            C.CameraID,
            C.NumVehicles,
            V.NumStolenVehicles,
            ((double)V.NumStolenVehicles / C.NumVehicles) * 100 AS PercentStolen
        FROM 
            @vehicleAnalysis AS C
        JOIN
            @stolenVehicleAnalysis AS V
        ON
            C.CameraID == V.CameraID;
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle4.usql**.

5. In AnalyzeSpeedsByVehicle.usql, replace the existing OUTPUT statement to save these results, and sort the data in descending order of PercentStolen:

    ```SQL
    OUTPUT @speedCameraAnalysis
    TO "/StolenVehicleSpeedAnalysis.csv"
    ORDER BY PercentStolen DESC
    USING Outputters.Csv(quoting : false, outputHeader : true);
    ```
    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle5.usql**.

6. In the **AnalyzeSpeedsByVehicle.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **master**, and then click **Submit**.
7. When the job has completed, close the **Job View** pane.
8. Switch to the Azure portal.
9. In the Data explorer blade, click **StolenVehicleSpeedAnalysis.csv**, and note that the data is now sorted in descending order of **PercentStolen**.
10. On the **File Preview** blade, click **Download**.
11. On the **Download** blade, click **Start Download now**.
12. In the Internet Explorer message box, click the **Save** drop-down arrow, and then click **Save as**.
13. In the **Save As** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise3**, and then click **Save**.
14. In the **Confirm Save As** dialog box, click **Yes**.
15. In the Internet Explorer message box, click **Open folder**.
16. In File Explorer, double-click **StolenVehicleSpeedAnalysis.csv**.
17. In Microsoft Excel, view the data, and note that there are now 500 records (one record for each camera, plus the header). The data should indicate that between 2.45 percent and 3.76 percent of all cars passing speed cameras are stolen.
18. Close Microsoft Excel.
19. Switch to the Azure portal, and close the **Download** and **File Preview** blades.

>**Result**: In this exercise, you uploaded speed camera data to ADLS, examined the code in the custom reducer, deployed and tested the custom reducer. You then used the reducer to identify stolen vehicles in the speed camera data.

## Exercise 4: Use existing analytics, developed in R, in an ADLA solution

### Task 1: Determining correlations by using R

1. In the Azure portal, click **All resources**, and then click **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
2. Under **GETTING STARTED**, click **Sample Scripts**.
3. On the **Sample Scripts** blade, click **Install U-SQL Extensions**, and then click **OK**.
4. When the installation has completed, close the **Sample Scripts** blade.
5. On the Windows **Start** menu, type **Notepad**, and then press Enter.
6. In Notepad, on the **File** menu, click **Open**.
7. In the **Open** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise4**, click **All Files (\*.\*)**, click **SpeedAnalytics.R**, and then click **Open**. This is an R script that uses the ScaleR package to tidy up the input data, calculate the correlation between a vehicle speeding and being stolen, and return a data frame containing the data from the correlation matrix; remember that the reducer will call this code once for each camera (the reducer will group the data by camera ID).
8. Close Notepad.
9. Return to the Azure portal.
10. Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data explorer**.
11. In the Data explorer blade, in the default folder, click **Upload**.
12. On the **Upload files** blade, click the **Select a file** button.
13. In the **Open** dialog box, go to the folder **E:\\Labfiles\\Lab06\\Exercise4**, click **SpeedAnalytics.R**, and then click **Open**.
14. On the **Upload files** blade, click **Add selected files**.
15. When the file has uploaded, close the **Upload files** blade.
16. On the desktop, switch to the instance of Visual Studio 2017 that has the **SpeedCameraAnalytics2** solution open.
17. In Solution Explorer, right-click **SpeedCameraAnalytics2**, point to **Add**, and then click **New Item**.
18. In the **Add New Item** dialog box, click **U-SQL Script**, in the **Name** box, type **AnalyzeUsingR.usql**, and then click **Add**.
19. In the **AnalyzeUsingR.usql** script, add the following statements to add references to the ExtR and CustomReducers assemblies:

    ```SQL
    REFERENCE ASSEMBLY [ExtR];
    REFERENCE ASSEMBLY CustomReducers;
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR1.usql**.

20. In the **AnalyzeUsingR.usql** script, add the following statements to retrieve the stolen vehicle history data, and use the ReduceByRecoveredVehicles to return only vehicles that are currently marked as stolen:

    ```SQL
    @stolenVehicleHistory =
        EXTRACT VehicleRegistration string,
            DateStolen string,
            DateRecovered string // Can be empty
        FROM "/Stolen/{*}/{*}/{*}/VehicleData.csv"
        USING Extractors.Csv(skipFirstNRows: 1);

    @stolenVehicles =
        REDUCE @stolenVehicleHistory
        ON VehicleRegistration
        PRODUCE VehicleRegistration string,
            DateStolen DateTime
        USING new CustomReducers.ReduceByRecoveredVehicles();
    ```

     You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR2.usql**.

21. In the **AnalyzeUsingR.usql** script, add the following statement to fetch the speed camera data from the catalog:

    ```SQL
    @speedData =
        SELECT
            CameraID,
            VehicleRegistration,
            Speed,
            SpeedLimit
        FROM
            VehicleData.dbo.SpeedCameraData;
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR3.usql**.

22. In the **AnalyzeUsingR.usql** script, add the following statements to combine the rowsets over the vehicle registration column, and to perform a LEFT join because you want to include all rows from the speed camera data regardless of whether or not the vehicle snapped was speeding:

    ```SQL
    @sourceData =
        SELECT
            C.CameraID AS CameraID,
            C.VehicleRegistration AS VehicleRegistration,
            C.Speed AS Speed,
            C.SpeedLimit AS SpeedLimit,
            V.DateStolen.ToString() AS DateStolen
        FROM
            @speedData AS C
        LEFT JOIN
            @stolenVehicles AS V
        ON
            C.VehicleRegistration == V.VehicleRegistration;
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR4.usql**.

    Note that this statement will cause the DateStolen column to have a null value in the resulting rowset for all cars that are not stolen.

23. In the **AnalyzeUsingR.usql** script, add the following statement to deploy the script containing the R code to be run:

    ```SQL
    DEPLOY RESOURCE @"/SpeedAnalytics.R";
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR5.usql**.

24. In the **AnalyzeUsingR.usql** script, add the following statement to call the R script to generate a correlation matrix for each camera, showing whether there is any correlation between cars speeding and being stolen:

    ```SQL
    @RScriptOutput =
        REDUCE @sourceData
        ON CameraID
        PRODUCE CameraID string, Correlation double
        USING new Extension.R.Reducer(scriptFile:"SpeedAnalytics.R", rReturnType:"dataframe", stringsAsFactors:false);
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR6.usql**:

25. In AnalyzeUsingR.usql, add the following statement to save the results:

    ```SQL
    OUTPUT @RScriptOutput
    TO "/CorrelationMatrixData.csv"
    ORDER BY CameraID
    USING Outputters.Csv(quoting : false, outputHeader : true);
    ```

    You can copy this code from the file **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR7.usql**.

26. In the **AnalyzeUsingR.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, set the database to **master**, and then click **Submit**.
27. When the job has completed, close the **Job View** pane.
28. Switch to the Azure portal.
29. In the Data explorer blade, click **CorrelationMatrixData.csv**, and review the results of the analysis. Note that there appears to be little correlation between cars being stolen and being caught speeding; this is not surprising for this dataset because all of the data is generated randomly. However, there might be more of a correlation in the real world.
30. Close the **File Preview** blade.

>**Result**: In this exercise, you used an R script script to analyze data in a U-SQL job.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
