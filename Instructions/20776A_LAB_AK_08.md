# Module 8: Performing Analytics with Azure SQL Data Warehouse

- [Module 8: Performing Analytics with Azure SQL Data Warehouse](#module-8-performing-analytics-with-azure-sql-data-warehouse)
    - [Lab: Performing analytics with SQL Data Warehouse](#lab-performing-analytics-with-sql-data-warehouse)
    - [Exercise 1: Visualize data stored in SQL Data Warehouse](#exercise-1-visualize-data-stored-in-sql-data-warehouse)
        - [Task 1: Prepare the environment](#task-1-prepare-the-environment)
        - [Task 2: Upload data to Blob storage](#task-2-upload-data-to-blob-storage)
        - [Task 3: Use PolyBase to transfer blob data to SQL Data Warehouse](#task-3-use-polybase-to-transfer-blob-data-to-sql-data-warehouse)
        - [Task 4: Use Power BI to visualize the data](#task-4-use-power-bi-to-visualize-the-data)
    - [Exercise 2: Use Machine Learning with SQL Data Warehouse](#exercise-2-use-machine-learning-with-sql-data-warehouse)
        - [Task 1: Create a trained model](#task-1-create-a-trained-model)
        - [Task 2: Construct a machine learning web service using the trained model](#task-2-construct-a-machine-learning-web-service-using-the-trained-model)
        - [Task 3: Deploy the machine learning web service](#task-3-deploy-the-machine-learning-web-service)
        - [Task 4: Generate predictions by using the machine learning web service in an application](#task-4-generate-predictions-by-using-the-machine-learning-web-service-in-an-application)
    - [Exercise 3: Assess SQL Data Warehouse query performance and optimize database configuration](#exercise-3-assess-sql-data-warehouse-query-performance-and-optimize-database-configuration)
        - [Task 1: Assess performance of a baseline query](#task-1-assess-performance-of-a-baseline-query)
        - [Task 2: Assess query performance when using replicated tables](#task-2-assess-query-performance-when-using-replicated-tables)
        - [Task 3: Assess query performance when distributing data by vehicle number](#task-3-assess-query-performance-when-distributing-data-by-vehicle-number)
        - [Task 4: Assess query performance when using a columnstore index](#task-4-assess-query-performance-when-using-a-columnstore-index)
        - [Task 5: Assess query performance when distributing linked data to the same node](#task-5-assess-query-performance-when-distributing-linked-data-to-the-same-node)
    - [Exercise 4: Configure SQL Data Warehouse auditing and analyze threats](#exercise-4-configure-sql-data-warehouse-auditing-and-analyze-threats)
        - [Task 1: Enable auditing and threat detection](#task-1-enable-auditing-and-threat-detection)
        - [Task 2: Generate audit and threat test data](#task-2-generate-audit-and-threat-test-data)
        - [Task 3: View audit logs and alerts](#task-3-view-audit-logs-and-alerts)
        - [Task 4: Monitor login failures](#task-4-monitor-login-failures)
        - [Task 5: Lab cleanup](#task-5-lab-cleanup)
  
## Lab: Performing analytics with SQL Data Warehouse

If you have not completed Lab 4 or Lab 7, use the following instructions to download and install AzCopy:

1. Ensure that the **MT17B-WS2016-NAT**, **20776A-LON-DC**, and **20776A-LON-DEV** virtual machines are running, and then log on to **20776A-LON-DEV** as **ADATUM\\AdatumAdmin** with the password **Pa55w.rd**.
2. Start **Internet Explorer** and go to **https://aka.ms/downloadazcopy**
3. In the Internet Explorer message box, click Run.
4. In the **Microsoft Azure Storage AzCopy** dialog box, on the **Welcome to the Microsoft Azure Storage AzCopy Setup Wizard** page, click **Next**.
5. On the **End-User License Agreement** page, select the **I accept the terms in the License Agreement** check box, and then click **Next**.
6. On the **Destination Folder** page, click **Next**.
7. On the **Ready to install Microsoft Azure Storage AzCopy** page, click **Install**.
8. In the **User Account Control** dialog box, click **Yes**.
9. On the **Completed the Microsoft Azure Storage AzCopy Setup Wizard** page, click **Finish**.
10. Right-click the Windows **Start** button, click **System**, and then click **Advanced system settings**.
11. In the **System Properties** dialog box, click **Environment Variables**.
12. In the **Environment Variables** dialog box, under **User variable for AdatumAdmin**, click **Path**, and then click **Edit**.
13. In the **Edit User Variable** dialog box, in the **Variable value** box, at the end of the existing text, type **C:\Program Files (x86)\Microsoft SDKs\Azure\AzCopy;**, and then click **OK**.
14. In the **Environment Variables** dialog box, click **OK**.
15. In the **System Properties** dialog box, click **OK**.
16. Close the System window.

## Exercise 1: Visualize data stored in SQL Data Warehouse

>**Note:** If you have completed Lab 4 or Lab 7, you do not need to complete Exercise 1, Task 1.

### Task 1: Prepare the environment

1. In the Azure portal, click **All resources**, and then click **trafficwarehouse**.
2. On the **trafficwarehouse** blade, click **Resume**, and then click **Yes**.
3. Wait until the database has started before continuing with the exercise.
4. On the desktop, on the Windows **Start** menu, type **Microsoft SQL Server Management Studio**, and then press Enter.
5. In the **Connect to Server** dialog box, in the **Server name** box, type **trafficserver&lt;_your name_&gt;&lt;_date_&gt;.database.windows.net**.
6. In the **Authentication** list, click **SQL Server Authentication**.
7. In the **Login** box, type **student**.
8. In the **Password** box, type **Pa55w.rd**, and then click **Connect**.
9. In Object Explorer, expand **trafficserver&lt;_your name_&gt;&lt;_date_&gt;.database.windows.net**, expand **Databases**, and then click **trafficwarehouse**.
10. On the **File** menu, point to **Open**, and then click **File**.
11. In the **Open File** dialog box, go to the folder **E:\\Labfiles\\Lab08\\Exercise1**, click **Exercise1.sql**, and then click **Open**.
12. In the SQL Editor, highlight the following command, and then click **Execute**:

    ```SQL
    DELETE FROM dbo.VehicleSpeed
    GO
    ```

    This statement clears out all existing data from the **VehicleSpeed** table in the data warehouse.

13. Switch to the Azure portal.
14. Click **+ Create a resource**, click **Storage**, and then click **Storage account - blob, file, table, queue**.
15. On the **Create storage account** blade, in the **Resource group** list, click **CamerasRG**.
16. In the **Storage account name** box, type **speeddata&lt;_your name_&gt;&lt;_date_&gt;**. 
17. In the **Location** list, select your nearest location.
18. In the **Account kind** list, click **Blob storage**.
19. Leave all other details at their defaults, and click **Review + create**, and then click **Create**.
20. Wait until the storage account has been successfully created before continuing with the exercise.
21. Click **All resources**, and then click **speeddata&lt;_your name_&gt;&lt;_date_&gt;**.
22. On the **speeddata&lt;_your name_&gt;&lt;_date_&gt;** blade, under **Blob Service**, click **Blobs**, and then click **+ Container**.
23. In the **New container** dialog box, in the **Name** box, type **capturedspeeds**, and then click **OK**.

### Task 2: Upload data to Blob storage

1. On the **speeddata&lt;_your name_&gt;&lt;_date_&gt;** **- Containers** blade, under **Settings**, click **Access keys**.
2. Next to **key1**, click the **Click to copy** button, to copy the key to the clipboard.
3. On the desktop, right-click the Windows **Start** button, and then click **Command Prompt (Admin)**.
4. In the **User Account Control** dialog box, click **Yes**.
5. At the command prompt, type the following command. Replace **&lt;storage account name&gt;** with **speeddata&lt;_your name_&gt;&lt;_date_&gt;**, and replace **&lt;storage account key&gt;** with the key you copied to the clipboard), and then press Enter:

    ```CMD
    azcopy /Source:"E:\Labfiles\Lab08\Exercise1" /Pattern:"SpeedData.csv" /Dest:https://<storage account name>.blob.core.windows.net/capturedspeeds /DestKey:<storage account key>
    ```

    This command uploads a new set of vehicle speed records to Blob storage.

    You can copy this command from the file **E:\\Labfiles\\Lab08\\Exercise1\\AZCopyCmd.txt**.

### Task 3: Use PolyBase to transfer blob data to SQL Data Warehouse

1. Switch to SQL Server Management Studio.
2. In the SQL Editor, locate the following command. Replace **&lt;storage account name&gt;** with **speeddata&lt;_your name_&gt;&lt;_date_&gt;**, and replace **&lt;storage account key&gt;** with the key you copied to the clipboard earlier:

    ```SQL
    CREATE DATABASE SCOPED CREDENTIAL SpeedDataCredentials
    WITH IDENTITY = '<storage account name>',
    SECRET = '<storage account key>';
    GO
    ```

3. Highlight the edited command, and on the toolbar, click **Execute**. This command will create a database scoped credential for accessing the **speeddata&lt;_your name_&gt;&lt;_date_&gt;** storage account.
4. In the SQL Editor, locate the following command. Replace **&lt;storage account name&gt;** with **speeddata&lt;_your name_&gt;&lt;_date_&gt;**:

    ```SQL
    CREATE EXTERNAL DATA SOURCE SpeedDataSource
    WITH (
        TYPE = HADOOP,
        LOCATION = 'wasbs://capturedspeeds@<storage account name>.blob.core.windows.net',
        CREDENTIAL = SpeedDataCredentials
    )
    GO
    ```

5. Highlight the edited command, and on the toolbar, click **Execute**. This command will create an external data source named **SpeedDataSource** that connects to the **capturedspeeds** container in the **speeddata*&lt;your name&gt;&lt;date&gt; ***Blob storage account using this credential.
6. In the SQL Editor, highlight the following command:

    ```SQL
    CREATE EXTERNAL TABLE ExternalSpeedData (
        CameraID VARCHAR(10) NOT NULL,
        SpeedLimit INT NOT NULL,
        Speed INT NOT NULL,
        VehicleRegistration VARCHAR(7) NOT NULL,
        WhenDate VARCHAR(20) NOT NULL,
        WhenMonth INT NOT NULL
    )
    WITH (
        LOCATION='SpeedData.csv',
        DATA_SOURCE = SpeedDataSource,
        FILE_FORMAT = CommaSeparatedFileFormat,
        REJECT_TYPE = percentage,
        REJECT_VALUE = 2,
        REJECT_SAMPLE_VALUE = 1000
    )
    GO
    ```

7. On the toolbar, click **Execute**. This command will create an external table named **ExternalSpeedData** that uses the data source and the **CommaSeparatedFileFormat** (from Lab 7) to read the location data from Blob storage. Note that the **REJECT\_VALUE** and **REJECT\_SAMPLE\_VALUE** settings allow for some minor corruption or malformed records in the CSV file.
8. In the SQL Editor, highlight the following command:

    ```SQL
    INSERT INTO dbo.VehicleSpeed(CameraID, SpeedLimit, Speed, VehicleRegistration, WhenDate, WhenMonth)
    SELECT CameraID, SpeedLimit, Speed, VehicleRegistration, CONVERT(DATETIME, WhenDate, 103) AS WhenDate, WhenMonth
    FROM ExternalSpeedData
    GO
    ```

9. On the toolbar, click **Execute**; this command will copy the data from the **ExternalSpeedData** table to the **dbo.VehicleSpeed** table. Note that the value in the **WhenDate** column is a string, which is converted into a **DateTime** by specifying the appropriate format style. When you execute this command, you might get one or two messages about rejected rows; you can ignore these errors.
10. In the SQL Editor, close **Exercise1.sql**, without saving any changes, but leave SQL Server Management Studio open.

### Task 4: Use Power BI to visualize the data

1. On the desktop, double-click the **Power BI Desktop** icon.
2. In the **Power BI Desktop** splash screen, click **Get data**.
3. In the **Get Data** dialog box, click **Azure**, click **Azure SQL Data Warehouse**, and then click **Connect**.
4. In the  **SQL Server database** dialog box, in the **Server** box type **trafficserver&lt;_your name_&gt;&lt;_date_&gt;.database.windows.net**, in the **Database** box type **trafficwarehouse**, click **DirectQuery**, and then click **OK**.
5. Click the **Database** tab.
6. In the **User name** box type **student**, in the **Password** box type **Pa55w.rd**, and then click **Connect**.
7. In the **Navigator** dialog box, click the check box for the **VehicleSpeed** table, and then click **Load**
8. In the **VISUALIZATIONS** pane, click **Line chart**.
9. In the **FIELDS** pane, expand **VehicleSpeed**, drag **WhenDate** to **Axis**, drag **CameraID** to **Legend**, and then drag **Speed** to **Values**.
10. Resize the graph to make it bigger.
11. In the **VISUALIZATIONS** pane, under **FILTERS**, click **CameraID(All)**.
12. In the **Filter Type** list, click **Basic filtering**, and then select the **Camera 0**, **Camera 1**, and **Camera 10** check boxes; note that, if you do not use the **Filters** pane at this point to select just one or two speed cameras, you might exceed the maximum number of data points allowed on a Power BI graph.
13. Click **Focus mode**.
14. On the **File** menu, click **Save as**.
15. In the **Save your report** dialog box, type **Vehicle Speeds over Time by CameraID**, and then click **Save**.
16. In the **FILTERS** pane, select a single camera.
17. Examine the graph, and notice how speeds vary throughout the day.
18. In the **FILTERS** pane, select another camera, and note the pattern; it should be similar to the first camera.

    Note that, if the system was using a Stream Analytics job to send data as it was captured to the SQL Data Warehouse, you could click **Refresh** periodically to see the most recent data. As it stands, the data warehouse just contains an historical snapshot of speed camera data.

19. Close the Power BI tab.

>**Result**: In this exercise, you uploaded data to Blob storage, and then used PolyBase to transfer this blob data to SQL Data Warehouse. You then used Power BI to visualize this data, and look for patterns in the data.

## Exercise 2: Use Machine Learning with SQL Data Warehouse

### Task 1: Create a trained model

1. In the Azure portal, click **All Resources**, and then click the **Traffic** machine learning workspace.
2. On the **Traffic** blade, under **Additional Links**, click **Launch Machine Learning Studio**.
3. On the **Microsoft Azure Machine Learning Studio** page, click **Sign in here**.
4. On the **My Experiments** page, click **+ NEW**, and then click **Blank Experiment**.
5. In the left pane, expand **Data Input and Output**, and then drag the **Import Data** module to the workspace canvas.
6. Click the **Import Data** module.
7. In the **Properties** pane, set the following values:
    - **Data source**: Azure SQL Database
    - **Database server name**: trafficserver&lt;_your name_&gt;&lt;_date_&gt;.database.windows.net
    - **Database name**: trafficwarehouse
    - **User name**: student
    - **Password**: Pa55w.rd
    - **Database query**:

    ```SQL
    SELECT CameraID, Speed, DATEPART(hour, WhenDate) AS Hour, DATEPART(weekday, WhenDate) AS Day FROM dbo.VehicleSpeed
    ```

    The query returns the Hour (0-23) and Day (1-7) rather than the date and time down to the nearest fraction of a millisecond, which would be much too low a level of granularity for generating a predictive model. We are more interested in knowing whether traffic will be slow between 5 and 6 PM on a Friday, rather than trying to guess what the speed will be at 17:37:42.6586 on a specific date.

8. In the left pane, expand **Data Transformation**, expand **Sample and Split**, and then drag the **Split Data** module to the workspace canvas, below the **Import Data** module.
9. Connect the output of the **Import Data** module to the input of the **Split Data** module.
10. Click the **Split Data** module.
11. In the **Properties** pane, set **Fraction of rows in the first output dataset** to **0.9**.
12. In the left pane, expand **Machine Learning**, expand **Initialize Model**, expand **Regression**, and then drag the **Decision Forest Regression** module to the workspace canvas, to the left of the **Split Data** module.
13. In the left pane, under **Machine Learning**, expand **Train**, and drag **Train Model** to the workspace canvas, below the **Split Data** and **Decision Network Regression** modules.
14. Connect the output from the **Decision Forest Regression** module to the left input of the **Train Model** module.
15. Connect the left output of the **Split Data** module to the right input of the **Train Model** module.
16. Click **Train Model**.
17. In the **Properties** pane, click **Launch column selector**.
18. In the **Select a single column** dialog box, in the second list box, click **column names**, and in the third box, type **Speed**.
19. Click the check mark (tick) to close the **column selector** dialog box.
20. In the left pane, under **Machine Learning**, expand **Score**, and drag the **Score Model** module to the workspace canvas, below and slightly to the right of the **Train Model** module.
21. Connect the output from the **Train Model** module to the left input of the **Score Model** module.
22. Connect the right output of the **Split Data** module to the right input of the **Score Model** module.
23. In the toolbar, click **SAVE**, and then click **RUN**. When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished; note that the experiment might take several minutes to complete.
24. When the experiment has finished, right-click the output of the **Score Model** module, and then click **Visualize**. Note that the **Scored Label Mean** column contains the predicted speeds for a given camera on a specified day at a particular time peiod made by the model, and the **Speed** column contains the actual speeds.
25. Close the visualization window.

### Task 2: Construct a machine learning web service using the trained model

1. Right-click the **Train Model** module, click **Trained model**, and then click **Save as Trained Model**.
2. In the **Save trained model** dialog box, in the **Name** box, type **Decision Forest Trained Regression Model for Vehicle Speeds**, and click **Ok** (tick).
3. Right-click the **Decision Forest Regression** module, and then click **Delete**.
4. Right-click the **Train Model** module, and then click **Delete**.
5. In the left pane, expand **Trained Models**, and then drag **Decision Forest Trained Regression Model for Vehicle Speeds** to the workspace canvas, to the left of the **Split Data** module.
6. Connect the output of the **Decision Forest Trained Regression Model for Vehicle Speeds** module to the left input of the **Score Model** module.
7. In the toolbar, click **SET UP WEB SERVICE**.
8. If the **STEP 1** dialog box appears, close it.
9. Right-click the connection from the **Web service input** module to the **Split Data** module, and then click **Delete**.
10. Connect the output of the **Web service input** module to the right input of the **Score Model** module.
11. In the toolbar, click **SAVE**, and then click **RUN** (to validate the changes). When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished.

### Task 3: Deploy the machine learning web service

1. In the toolbar, click **DEPLOY WEB SERVICE**, and then click **Deploy Web Service [Classic]**.
2. Copy the **API key** to the clipboard.
3. On the desktop, start Notepad
4. In Notepad type the text **Web service API key**, press Enter to create a new line, and then paste the API key.
5. On the *File** menu click **Save**, and save the file as **E:\\Labfiles\\Lab08\\Exercise2\\Config\_details.txt**.
6. Return to Microsoft Azure Machine Learning Studio.
7. On the **experiment created on *&lt;date&gt;*** page, click **New Web Services Experience**.
8. On the **default** page, under **BASICS**, click **Configure endpoint**.
9. In the **Description** box, type **Vehicle speed prediction web service**, and then click **Save**.
10. In the toolbar, click **Quickstart**, and then click **Use endpoint**.
11. Next to **Request-Response**, click the **Copy** button.
12. Switch to Notepad.
13. In Notepad, click at the end of the file, press Enter to create a new line, type **Request-Response URL**, press Enter to create a new line, and then paste the Request-Response URL.
14. On the **File** menu, click **Save**

### Task 4: Generate predictions by using the machine learning web service in an application

1. On the Windows **Start** menu, type **Visual Studio 2017**, and then press Enter.
2. In Visual Studio, click on the **File** menu, click **Open**, and then click **Project/Solution**.
3. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab08\\Exercise2\\VehicleSpeedPredictor** folder, click **VehicleSpeedPredictor.sln**, and then click **Open**.
4. In Solution Explorer, double-click the **App.config** file.
5. In App.config, in the **appSettings** section, replace the APIKey value **&lt;YourApiKey&gt;** with the API key of the web service that you copied to the **Config\_details.txt** file in Notepad.
6. Replace the URL value **&lt;YourEndpointUrl&gt;** with the **Request-Response URL** that you copied to Config\_details.txt.

    > **IMPORTANT**: Replace the **&** character near the end of the Request-Response URL (before the text **format=swagger**) with the sequence **&\#x26;** this is necessary because the **&** character is interpreted as an escape character in XML rather than a literal. The sequence **&\#x26;** generates a literal **&**.

7. On the **Build** menu, click **Build VehicleSpeedPredictor**. Verify that the app compiles successfully.
8. On the **Debug** menu, click **Start Without Debugging**.
9. At the **Enter a camera ID** prompt, type any number between 0 and 499, and then press Enter.
10. At the **Enter an hour** prompt, type any number between 0 and 23, and then press Enter.
11. At the **Enter a day** prompt, type any number between 1 and 7 (where day 1 is Sunday, and day 7 is Saturday), and then press Enter.
12. After a few moments, the predicted speed at that time for that camera will be displayed.
13. Repeat steps 9-13 several times for other cameras, dates, and times.
14. Close Visual Studio.
15. In Internet Explorer, close the web services tabs.

> **Result**: In this exercise, you created a trained model, deployed this model as a web service, and then used this service in an application to generate traffic speed predictions for particular camera locations, at particular times of day, and for particular days of the week.

## Exercise 3: Assess SQL Data Warehouse query performance and optimize database configuration

### Task 1: Assess performance of a baseline query

1. Return to SQL Server Management Studio, and ensure that you are still connected to **trafficserver&lt;your name&gt;&lt;date&gt;** (reconnect using SQL Server authentication, with the login name **student** and password **Pa55w.rd** if necessary).
2. On the **File** menu, click **Open**, and then click **File**.
3. In the **Open File** dialog box, go to the **E:\\Labfiles\\Lab08\\Exercise3** folder, click **Exercise3.sql**, and then click **Open**.
4. In the toolbar, ensure that the **trafficwarehouse** database is selected.
5. In the SQL Editor, highlight the following command, and then click **Execute**:

    ```SQL
    SELECT V.VehicleRegistration
    FROM dbo.VehicleOwner V
    WHERE V.VehicleRegistration NOT IN
    (
        SELECT S.VehicleRegistration
        FROM dbo.VehicleSpeed S
        WHERE S.Speed > S.SpeedLimit
    )
    ORDER BY V.VehicleRegistration
    GO
    ```

   Wait for the query to finish. It should fetch over 7 million rows.
6. Repeat step 5 twice more to execute the query another couple of times.
7. Switch to the Azure portal.
8. In the Azure portal, click **All Resources**, and then click **trafficwarehouse**.
9. On the **trafficwarehouse** blade, in the **Common Tasks** section, click **Monitoring**.
10. On the **Monitoring** blade, click the **Query Activity** graph.
11. On the **Queries** blade, click the **Start Time** column twice to order the queries by time, with the most recent at the top.
12. Click the most recent query that was run by the **student** login.
13. On the **Query Details** blade, click **Show Query Text**. The text should match the query you performed in Step 5.
14. Close the **Query Text** blade.
15. On the **Query Details** blade, click **Show Query Plan**. The Query Plan lists the steps performed by SQL Data Warehouse to run the query.
16. On the **Query Plan** blade, click the first **OnOperation** operation.
17. In the **Query Step Details** blade, click **Show Query Step Command**. The Query Step Text shows that SQL Data Warehouse creates a temporary table for storing vehicle registration numbers, and this table is created on every node in the data warehouse.
18. Close the **Query Step Text** blade.
19. On the **Query Plan** blade, click the **ShuffleMoveOperation** operation.
20. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** shows that **VehicleSpeed** data for vehicles that have been caught speeding is copied from every node in the data warehouse to the temporary table. This is the data for the inner subquery of the SELECT statement. This is a potentially expensive operation, as it could involve moving lots of data between nodes.
21. Close the **Query Step Text** blade.
22. On the **Query Plan** blade, click the second **OnOperation** operation.
23. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** shows that the query creates a second temporary table, also holding vehicle registration numbers.
24. Close the **Query Step Text** blade.
25. On the **Query Plan** blade, click the second **ShuffleMoveOperation** operation.
26. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** shows that **VehicleOwner** data for all vehicles is copied from every node in the data warehouse to the second temporary table. This is the data for the outer query in the SELECT statement. This is another potentially expensive operation.
27. Close the **Query Step Text** blade.
28. On the **Query Plan** blade, click the **ReturnOperation** operation.
29. On the **Query Step Details** blade, click **Show Query Step Command**. This step uses the data in the temporary tables in each node to find vehicles that have not been caught speeding. The details from each node are aggregated and returned as the overall results.
30. Close the **Query Step Text** blade.
31. Click the third **OnOperation** operation.
32. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** deletes the second temporary table from each node when the query has finished. 
33. Close the **Query Step Text** blade.
34. Click the final **OnOperation** operation.
35. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** deletes the firt temporary table from each node when the query has finished. 

    > **Note**: The temporary tables are required because the vehicle registration information and the vehicle speed information are both distributed throughout the nodes in the data warehouse. While this distribution enables SQL Data Warehouse to manage the load more evenly and reduce the chances of contention, it causes extra work and data movement for some queries. If you perform these queries often, you should consider modifying the distribution policies of the tables used.

36. Close the **Query Step Text**, **Query Step Details**, **Query Plan**, **Query Details**, and **Queries**, and **Monitoring** blades.

### Task 2: Assess query performance when using replicated tables

1. Switch to SQL Server Management Studio.
2. In the SQL Editor, highlight the following command, and then click **Execute**:

    ```SQL
    SELECT T.name, P.distribution_policy_desc
    FROM sys.pdw_table_distribution_properties P
    JOIN sys.tables T
    ON P.object_id = T.object_id
    GO
    ```

    This query displays the name of each table in the data warehouse and the distribution policy it uses. Note that the **VehicleOwner** table implements the **ROUND\_ROBIN** policy. The **VehicleSpeed** table is **HASH** (you should recall that the **CameraID** is used as the hash column).

3. In the SQL Editor, highlight the following command, and then click **Execute**:

    ```SQL
    DBCC PDW_SHOWSPACEUSED('VehicleOwner')
    GO
    ```

    This command shows how much space the **VehicleOwner** table occupies. The statistics in the various "space" columns are all measured in KB. The **VehicleOwner** table currently consumes between 11.5 and 12.5 MB in each node. In general, if a relatively static fact table is smaller than 2 GB, you should consider implementing it as a replicated table. This approach might reduce the chances of data movement, because the same data is automatically available on every node.

4. In the SQL Editor, highlight the following commands, and then click **Execute**:

    ```SQL
    CREATE TABLE VehicleOwner2
    (
        VehicleRegistration VARCHAR(7) NOT NULL,
        Title VARCHAR(30) NOT NULL,
        Forename VARCHAR(30) NOT NULL,
        Surname VARCHAR(30) NOT NULL,
        AddressLine1 VARCHAR(50) NOT NULL,
        AddressLine2 VARCHAR(50) NOT NULL,
        AddressLine3 VARCHAR(50) NOT NULL,
        AddressLine4 VARCHAR(50) NOT NULL
    )
    WITH
    (
        DISTRIBUTION = REPLICATE
    )
    GO

    INSERT INTO VehicleOwner2
    SELECT *
    FROM VehicleOwner
    GO
    ```

    These commands create a new version of the **VehicleOwner** table (VehicleOwner2) that is replicated. The **INSERT** statement copies the data into this new table.

5. In the SQL Editor, highlight the following command, and then click **Execute**:

    ```SQL
    SELECT V.VehicleRegistration
    FROM dbo.VehicleOwner2 V
    WHERE V.VehicleRegistration NOT IN
    (
        SELECT S.VehicleRegistration
        FROM dbo.VehicleSpeed S
        WHERE S.Speed > S.SpeedLimit
    )
    ORDER BY V.VehicleRegistration
    GO
    ```

    Verify that this query returns the same number of rows as before. However, it might not be any faster than the previous query (it might actually be a little slower, at least for the first time).

6. Repeat Step 5 twice more to execute the query another couple of times.
7. Switch to the Azure portal.
8. On the **trafficwarehouse** blade, in the **Common Tasks** section, click **Monitoring**.
9. On the **Monitoring** blade, click the **Query Activity** graph.
10. On the **Queries** blade, click the **Start Time** column twice to order the queries by time, with the most recent at the top.
11. Click the most recent query that was run by the **student** login.
12. On the **Query Details** blade, click **Show Query Text**, and verify that the text matches the query you performed in Step 5.
13. Close the **Query Text** blade.
14. On the **Query Details** blade, click **Show Query Plan**, and note that the Query Plan now comprises five steps (numbered 0 to 4).
15. On the **Query Plan** blade, click the first **OnOperation** operation.
16. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** shows that SQL Data Warehouse is still creating a temporary table for storing vehicle registration numbers on every node in the data warehouse.
17. Close the **Query Step Text** blade.
18. On the **Query Plan** blade, click the **BroadcastMoveOperation** operation.
19. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Text step** shows that **VehicleOwner** data for vehicles that have been caught speeding is still being copied from every node in the data warehouse to the temporary table.
20. Close the **Query Step Text** blade.
21. On the **Query Plan** blade, click the **ReturnOperation** operation.
22. On the **Query Step Details** blade, click **Show Query Step Command**. Note that this time, there is no need to create a second temporary table because the Vehicle owner data has been replicated to every node.
23. Close the **Query Step Text** blade.
24. On the **Query Plan** blade, click the second **OnOperation** operation.
25. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** deletes the temporary table from each node when the query has finished.
26. Close the **Query Step Text**, **Query Step Details**, **Query Plan**, **Query Details**, **Queries**, and **Monitoring** blades.

    > **Note**: Although the **VehicleOwner** data is now replicated to each node, the **VehicleSpeed** data is distributed by speed camera ID. One possible idea is that you need to reorganize the speed data by vehicle registration number to ensure that the records for a single vehicle are all held together in the same node.

### Task 3: Assess query performance when distributing data by vehicle number

1. Switch to SQL Server Management Studio.
2. In the SQL Editor, highlight the following commands, and then click **Execute**:

    ```SQL
    CREATE TABLE VehicleSpeed2
    (
        CameraID VARCHAR(10) NOT NULL,
        SpeedLimit INT NOT NULL,
        Speed INT NOT NULL,
        VehicleRegistration VARCHAR(7) NOT NULL,
        WhenDate DATETIME NOT NULL,
        WhenMonth INT NOT NULL
    )
    WITH
    (
        HEAP,
        DISTRIBUTION = HASH(VehicleRegistration),
        PARTITION (WhenMonth RANGE FOR VALUES(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
    )

    GO
    INSERT INTO VehicleSpeed2
    SELECT *
    FROM VehicleSpeed
    GO
    ```

    These statements create a copy of the **VehicleSpeed** table that is distributed by **VehicleRegistration** number rather than camera ID. The table is created as a **HEAP** (as was the original table).

3. In the SQL Editor, highlight the following query, and then click **Execute**:

    ```SQL
    SELECT V.VehicleRegistration
    FROM dbo.VehicleOwner2 V
    WHERE V.VehicleRegistration NOT IN
    (
        SELECT S.VehicleRegistration
        FROM dbo.VehicleSpeed2 S
        WHERE S.Speed > S.SpeedLimit
    )
    ORDER BY V.VehicleRegistration
    GO
    ```

    This is the same query as before, except that it now references the reorganized version of the **VehicleSpeed** table.

4. Repeat Step 3 twice more, to execute the query another couple of times.
5. Switch to the Azure portal.
6. On the **trafficwarehouse** blade, in the **Common Tasks** section, click **Monitoring**.
7. On the **Monitoring** blade, click the **Query Activity** graph.
8. On the **Queries** blade, click the **Start Time** column twice to order the queries by time, with the most recent at the top.
9. Click the most recent query that was run by the **student** login.
10. On the **Query Details** blade, click **Show Query Text**, and verify that the text matches the query you performed in Step 3.
11. Close the **Query Text** blade.
12. On the **Query Details** blade, click **Show Query Plan**, and note that the Query Plan still comprises five steps (numbered 0 to 4).
13. On the **Query Plan** blade, click the first **OnOperation** operation.
14. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** shows that SQL Data Warehouse is still creating a temporary table for storing vehicle registration numbers on every node in the data warehouse.
15. Close the **Query Step Text** blade.
16. On the **Query Plan** blade, click the **BroadcastMoveOperation** operation.
17. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Text** step shows that **VehicleOwner** data for vehicles that have been caught speeding is still being copied from every node in the data warehouse to the temporary table.
18. Close the **Query Step Text** blade.
19. On the **Query Plan** blade, click the **ReturnOperation** operation.
20. On the **Query Step Details** blade, click **Show Query Step Command**. Again, this step uses the data in the temporary table in each node to find vehicles that have not been caught speeding.
21. Close the **Query Step Text** blade.
22. On the **Query Plan** blade, click the second **OnOperation** operation.
23. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** deletes the temporary table from each node when the query has finished.
24. Close the **Query Step Text**, **Query Step Details**, **Query Plan**, **Query Details**, **Queries**, and **Monitoring** blades. 
    
    You suspect that implementing the **VehicleSpeed** table as a heap might be the reason for the query to create a temporary table and move data around.. Perhaps it’s better to index this data as a **ColumnStore** structure.

### Task 4: Assess query performance when using a columnstore index

1. Switch to SQL Server Management Studio.
2. In the SQL Editor, highlight the following command, and then click **Execute**. The **VehicleSpeed3** table uses the defult option (a columnstore index) for organizing the data:

    ```SQL
    CREATE TABLE VehicleSpeed3
    (
        CameraID VARCHAR(10) NOT NULL,
        SpeedLimit INT NOT NULL,
        Speed INT NOT NULL,
        VehicleRegistration VARCHAR(7) NOT NULL,
        WhenDate DATETIME NOT NULL,
        WhenMonth INT NOT NULL
    )
    WITH
    (
        DISTRIBUTION = HASH(VehicleRegistration),
        PARTITION (WhenMonth RANGE FOR VALUES(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
    )
    GO

    INSERT INTO VehicleSpeed3
    SELECT *
    FROM VehicleSpeed
    GO
    ```

3. In **Object Explorer**, expand **trafficwarehouse**, right-click **Tables**, and then cick **Refresh**.
4. Expand **Tables**, expand **dbo.VehicleSpeed3**, expand **Indexes**, and verify thatthe table has a clustered columnstore index.
5. In the SQL Editor, highlight the following command, and then click **Execute**:

    ```SQL
    SELECT V.VehicleRegistration
    FROM dbo.VehicleOwner2 V
    WHERE V.VehicleRegistration NOT IN
    (
        SELECT S.VehicleRegistration
        FROM dbo.VehicleSpeed3 S
        WHERE S.Speed > S.SpeedLimit
    )
    ORDER BY V.VehicleRegistration
    GO
    ```

    Note that this time the query might be much slower than in previous examples.

6. Repeat Step 5 twice more to execute the query another couple of times.
7. Switch to the Azure portal.
8. On the **trafficwarehouse** blade, in the **Common Tasks** section, click **Monitoring**.
9. On the **Monitoring** blade, click the **Query Activity** graph.
10. On the **Queries** blade, click the **Start Time** column twice to order the queries by time, with the most recent at the top.
11. Click the most recent query that was run by the **student** login.
12. On the **Query Details** blade, click **Show Query Text**, and verify that the text matches the query you performed in Step 3.
13. Close the **Query Text** blade.
14. On the **Query Details** blade, click **Show Query Plan**, and note that the Query Plan still comprises five steps (numbered 0 to 4).
15. On the **Query Plan** blade, click the first **OnOperation** operation.
16. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** shows that SQL Data Warehouse is still creating a temporary table.
17. Close the **Query Step Text** blade.
18. On the **Query Plan** blade, click the **BroadcastMoveOperation** operation.
19. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Text** step shows that data is still being copied from every node in the data warehouse to the temporary table.
20. Close the **Query Step Text** blade.
21. On the **Query Plan** blade, click the **ReturnOperation** operation.
22. On the **Query Step Details** blade, click **Show Query Step Command**. As before, this step uses the data in the temporary table in each node.
23. Close the **Query Step Text** blade.
24. On the **Query Plan** blade, click the second **OnOperation** operation.
25. On the **Query Step Details** blade, click **Show Query Step Command**. The **Query Step Text** deletes the temporary table from each node when the query has finished.
26. Close the **Query Step Text**, **Query Step Details**, **Query Plan**, **Query Details**, **Queries**, and **Monitoring** blades.

    > **Note**: The poor query performance is due to the way in which the query is executed. The query optimizer has to drive the query from the replicated table to find all **VehicleOwner** records that have no matching speed records. The query fetches the speed data from all nodes to compare against a single instance of the replicated vehicle registration table. If the query could drive from the **VehicleSpeed** table instead, it could quickly look up the necessary data locally in each node and avoid the data movement. The idea, therefore, is to ensure that the data in the **VehicleOwner** and **VehicleSpeed** tables are distributed in the same way.

### Task 5: Assess query performance when distributing linked data to the same node

1. Switch to SQL Server Management Studio.
2. In the SQL Editor, highlight the following commands, and then click **Execute**:

    ```SQL
    CREATE TABLE VehicleOwner3
    (
        VehicleRegistration VARCHAR(7) NOT NULL,
        Title VARCHAR(30) NOT NULL,
        Forename VARCHAR(30) NOT NULL,
        Surname VARCHAR(30) NOT NULL,
        AddressLine1 VARCHAR(50) NOT NULL,
        AddressLine2 VARCHAR(50) NOT NULL,
        AddressLine3 VARCHAR(50) NOT NULL,
        AddressLine4 VARCHAR(50) NOT NULL
    )
    WITH
    (
        DISTRIBUTION = HASH(VehicleRegistration)
    )

    GO
    INSERT INTO VehicleOwner3
    SELECT *
    FROM VehicleOwner
    GO
    ```

    These commands create another version of the **VehicleOwner** table, hashed by registration number. This matches the distribution policy of the **VehicleSpeed** table, so vehicle ownership and speed records for any given vehicle should now be held in the same node in the data warehouse.

3. In the SQL Editor, highlight the following command, and then click **Execute**:

    ```SQL
    SELECT V.VehicleRegistration
    FROM dbo.VehicleOwner3 V
    WHERE V.VehicleRegistration NOT IN
    (
        SELECT S.VehicleRegistration
        FROM dbo.VehicleSpeed3 S
        WHERE S.Speed > S.SpeedLimit
    )
    ORDER BY V.VehicleRegistration
    GO
    ```

4. Repeat Step 3 twice more to execute the query another couple of times.
5. Switch to the Azure portal.
6. On the **trafficwarehouse** blade, in the **Common Tasks** section, click **Monitoring**.
7. On the **Monitoring** blade, click the **Query Activity** graph.
8. On the **Queries** blade, click the **Start Time** column twice to order the queries by time, with the most recent at the top.
9. Click the most recent query that was run by the **student** login.
10. On the **Query Details** blade, click **Show Query Text**, and verify that the text matches the query you performed in Step 3.
11. Close the **Query Text** blade.
12. On the **Query Details** blade, click **Show Query Plan**, and note that this time the Query Plan contains a single **ReturnOperation** step.
13. On the **Query Plan** blade, click the **ReturnOperation** operation.
14. On the **Query Step Details** blade, click **Show Query Step Command**. This step shows that the data is retrieved from each node without creating a temporary table or moving data between nodes.
15. Close the **Query Step Text**, **Query Step Details**, **Query Plan**, **Query Details**, **Queries**, and **Monitoring** blades.
16. Close SQL Server Management Studio.

> **Result**: In this exercise, you ran a series of queries against SQL Data Warehouse, assessed how each query was processed, and reconfigured the data structures several times to see the impact on the query execution.

## Exercise 4: Configure SQL Data Warehouse auditing and analyze threats

### Task 1: Enable auditing and threat detection

1. In the Azure portal, on the **trafficwarehouse** blade, under **Security**, click **Auditing & Threat Detection**.
2. On the **trafficwarehouse -** **Auditing & Threat Detection** blade, under **Auditing**, click **ON**, and then click **Storage details**.
3. On the **Storage settings** blade, click **Storage account**.
4. On the **Create storage account** blade, in the **Name** box, type **auditdata&lt;_your name_&gt;&lt;_date_&gt;**, and then click **OK**. Wait until the storage account has been successfully created before continuing with the exercise.
5. On the **Storage settings** blade, click **OK**.
6. On the **trafficwarehouse -** **Auditing & Threat Detection** blade, under **Auditing**, click **Audited events**.
7. Verify that all events are selected, and then click **OK**.
8. On the **trafficwarehouse -** **Auditing & Threat Detection** blade, under **Threat Detection**, click **ON**, and then click **Threat Detection types**.
9. Verify that all types are selected, and then click **OK**.
10. In the **Send alerts to** box, type your own email address, or the email address of your Azure Learning Pass account.
11. Ensure that **Email service and co-administrators** is selected, click **Save**, and then click **OK**.

### Task 2: Generate audit and threat test data

1. On the Windows **Start** menu, type **Visual Studio 2017**, and then press Enter.
2. In Visual Studio, on the **File** menu, click **Open**, and then click **Project/Solution**.
3. In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab08\\Exercise4\\Threaten** folder, click **Threaten.sln**, and then click **Open**.
4. In Solution Explorer, double-click the **App.config** file.
5. In App.config, in the **appSettings** section, replace the Server value **&lt;YourServerName&gt;** with **trafficserver&lt;_your name_&gt;&lt;_date_&gt;**.
6. In Solution Explorer, double-click **Program.cs**.
7. View the code in the **RunQuery** method. This code showsa classic example of a SQL injection vulnerability. The code runs a SELECT statement to retrieve data using criteria specified by the user. The code makes no attempt to validate the user input, and the user can provide a string that contains all sorts of “nasty stuff”.
8. On the **Build** menu, click **Build Threaten**.
9. Verify that the app compiles successfully.
10. On the **Debug** menu, click **Start Without Debugging**.
11. At the application prompt, type **AAA 111**, and then press Enter. The application will attempt to find how many stolen vehicle records there are for this registration (0).
12. Press any key to close the app console window.
13. On the **Debug** menu, click **Start Without Debugging**.
14. At the application prompt, type **HSZ 883**, and then press Enter. The application will attempt to find how many stolen vehicle records there are for this registration (this vehicle has been reported stolen once).
15. Press any key to close the app console window.
16. On the **Debug** menu, click **Start Without Debugging**.
17. At the application prompt, type **H%**, and then press Enter. This time, the application will display how many times vehicles with a registration number that begins with the letter H have been stolen (59372).
18. Press any key to close the app console window.
19. On the **Debug** menu, click **Start Without Debugging**.
20. At the application prompt, type the following text on a single line, and then press Enter:

    ```SQL
    H%'; DROP TABLE Test; --
    ```

    This query returns the same number of rows, but also causes a DROP TABLE command to be run; the DROP TABLE command is effectively appended to the end of the SELECT statement. The first quote in the data finishes off the string expected by the SELECT statement. The semicolon starts a new statement, and the "--" starts a comment, which causes the final quote character in the string added by the application to be ignored, so that it doesn't cause a syntax error that would make the command fail.

    This is extremely dangerous. The application has effectively provided a back door into your database and a malicious user could access and damage your data.

    Fortunately, enabling threat detection causes SQL Data Warehouse to recognize this situation, and the injected command (DROP TABLE Test) will not be run.

21. Press any key to close the app console window.

### Task 3: View audit logs and alerts

1. Open the inbox for the email address you used in the previous task; steps will vary, depending on the email provider.
2. You should have a message from SQL Data Warehouse warning you that a potential SQL injection attack has occurred. Note that this email includes information on:
    - The target Azure subscription
    - The target Azure SQL Server and the database
    - The IP address of the source of the attack
    - The date and time of the attack
    - Potential causes and recommendations
3. Switch to the Azure portal.
4. On the **trafficwarehouse - Auditing & Threat Detection** blade, click **View audit logs**. Note the list of all recent actions and queries that have been performed.
5. Near the top of the list, you should see an entry with event type **DataAccess**, and another of type **SchemaChanges**; the **ACTION STATUS** of both records should be **Failure**. This indicates that SQL Data Warehouse detected a problem and did not run these statements.
6. Click the **SchemaChanges** record.
7. On the **Audit record** blade, examine the statement, which should look like this:

    ```SQL
    SELECT COUNT(*) FROM dbo.StolenVehicle WHERE VehicleRegistration LIKE 'H%'; DROP TABLE Test; -- '
    ```

   You can see how the user input has been appended to the query to perform the DROP TABLE operation.

8. Examine the older records with event type **DataAccess** from previous runs of the application; these statements should all have an action status of success, and indicate operations that were performed successfully.

### Task 4: Monitor login failures

1. Return to Visual Studio.
2. Double-click **App.config**.
3. Edit the **Password** value, and set it to a random string.
4. On the **Build** menu, click **Build Threaten**. Verify that the app compiles successfully.
5. On the **Debug** menu, click **Start Without Debugging**.
6. At the application prompt, type **H%**, and then press Enter. This time the application should stop with a “Login failed” exception.
7. Press any key to close the app console window.
8. Switch to the Azure portal.
9. On the **Audit records** blade, click **Refresh** to see the most recent records. This might take a few minutes to update.
10. Note that there is now a **Login** record with an **ACTION STATUS** of **Failure**.
11. Click the **Login Failure** record.Note that the record details include the IP address of the client application. Such information is useful so that, if necessary, you could block this IP address in the firewall of the database server.

### Task 5: Lab cleanup

1. Close the **Audit record**, and **Audit records** blades.
2. On the **trafficwarehouse – Auditing & Threat Detection** blade, click **Overview**, click **Pause**, and then click **Yes**.
3. On the desktop, close Visual Studio.

> **Result**: In this exercise, you enabled auditing, and used a sample application that includes a SQL injection vulnerability to attempt to attack the data warehouse. You also examined the audit logs, including identifying login failures.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
